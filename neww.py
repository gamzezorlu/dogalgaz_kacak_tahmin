import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="DoÄŸalgaz KaÃ§ak Tespit Sistemi",
    page_icon="ğŸ”¥",
    layout="wide"
)

st.title("ğŸ”¥ DoÄŸalgaz KaÃ§ak Tespit Sistemi")
st.markdown("---")

# Yan panel
st.sidebar.header("ğŸ“ Dosya YÃ¼kleme")
uploaded_file = st.sidebar.file_uploader(
    "CSV veya Excel dosyasÄ± seÃ§in",
    type=['csv', 'xlsx', 'xls']
)

# Parametreler
st.sidebar.header("âš™ï¸ Tespit Parametreleri")

normal_kis_esik = st.sidebar.slider(
    "Normal kÄ±ÅŸ tÃ¼ketimi eÅŸiÄŸi (mÂ³/ay)",
    min_value=50, max_value=200, value=80,
    help="Bu deÄŸerin Ã¼zerindeki kÄ±ÅŸ tÃ¼ketimi 'normal' kabul edilir"
)

dusuk_tuketim_esik = st.sidebar.slider(
    "DÃ¼ÅŸÃ¼k tÃ¼ketim eÅŸiÄŸi (mÂ³/ay)",
    min_value=5, max_value=50, value=20,
    help="Bu deÄŸerin altÄ±ndaki tÃ¼ketim 'kaÃ§ak ÅŸÃ¼phesi' kabul edilir"
)

ani_dusus_orani = st.sidebar.slider(
    "Kritik dÃ¼ÅŸÃ¼ÅŸ oranÄ± (%)",
    min_value=50, max_value=95, value=80,
    help="Normal tÃ¼ketime gÃ¶re bu oranda dÃ¼ÅŸÃ¼ÅŸ kaÃ§ak ÅŸÃ¼phesi oluÅŸturur"
)

min_normal_ay = st.sidebar.slider(
    "Minimum normal tÃ¼ketim ayÄ±",
    min_value=3, max_value=12, value=6,
    help="KaÃ§ak tespiti iÃ§in en az kaÃ§ ay normal tÃ¼ketim olmalÄ±"
)

def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        st.error(f"Dosya yÃ¼kleme hatasÄ±: {str(e)}")
        return None

def parse_date_columns(df):
    date_columns = []
    other_columns = []
    
    for col in df.columns:
        if isinstance(col, str) and '/' in col:
            try:
                year, month = col.split('/')
                if len(year) == 4 and 1 <= int(month) <= 12:
                    date_columns.append(col)
                else:
                    other_columns.append(col)
            except:
                other_columns.append(col)
        else:
            other_columns.append(col)
    
    return sorted(date_columns), other_columns

def get_season(month):
    if month in [12, 1, 2]:
        return "KÄ±ÅŸ"
    elif month in [3, 4, 5]:
        return "Ä°lkbahar"
    elif month in [6, 7, 8]:
        return "Yaz"
    else:
        return "Sonbahar"

def analyze_leak_patterns(df, date_columns, tesisat_col, bina_col):
    """GELÄ°ÅTÄ°RÄ°LMÄ°Å KAÃ‡AK TESPÄ°T ANALÄ°ZÄ°"""
    results = []
    
    for idx, row in df.iterrows():
        tesisat_no = row[tesisat_col]
        bina_no = row[bina_col]
        
        # TÃ¼m aylÄ±k verileri topla
        monthly_data = []
        for date_col in date_columns:
            try:
                value = row[date_col]
                if pd.notna(value):
                    year, month = date_col.split('/')
                    monthly_data.append({
                        'year': int(year),
                        'month': int(month),
                        'consumption': float(value),
                        'season': get_season(int(month)),
                        'date_str': date_col
                    })
            except:
                continue
        
        if len(monthly_data) < 6:
            continue
        
        cons_df = pd.DataFrame(monthly_data)
        cons_df = cons_df.sort_values(['year', 'month'])
        
        # ===========================================
        # KAÃ‡AK TESPÄ°T MANTIKLARI
        # ===========================================
        
        anomalies = []
        leak_score = 0  # KaÃ§ak puanÄ± (0-100)
        
        # 1. ZAMAN SERÄ°SÄ° ANALÄ°ZÄ° - Normal dÃ¶nem ve dÃ¼ÅŸÃ¼k dÃ¶nem tespiti
        cons_df['is_normal'] = cons_df['consumption'] >= normal_kis_esik
        cons_df['is_low'] = cons_df['consumption'] < dusuk_tuketim_esik
        cons_df['is_zero'] = cons_df['consumption'] == 0
        
        normal_months = cons_df[cons_df['is_normal']]
        low_months = cons_df[cons_df['is_low']]
        zero_months = cons_df[cons_df['is_zero']]
        
        # 2. DÃ–NEMSEL ANALÄ°Z - Ä°lk dÃ¶nem vs Son dÃ¶nem
        total_months = len(cons_df)
        first_half = cons_df.iloc[:total_months//2]
        second_half = cons_df.iloc[total_months//2:]
        
        first_half_avg = first_half['consumption'].mean()
        second_half_avg = second_half['consumption'].mean()
        
        # 3. KIÅ AYLARINDA ANALÄ°Z
        kis_aylari = cons_df[cons_df['season'] == 'KÄ±ÅŸ'].copy()
        
        if len(kis_aylari) > 0:
            # KÄ±ÅŸ aylarÄ±nÄ± yÄ±llara gÃ¶re grupla (AralÄ±k + Ocak + Åubat = bir kÄ±ÅŸ)
            kis_aylari['kis_sezonu'] = kis_aylari.apply(
                lambda x: f"{x['year']-1}/{x['year']}" if x['month'] in [1, 2] 
                else f"{x['year']}/{x['year']+1}",
                axis=1
            )
            
            kis_sezon_avg = kis_aylari.groupby('kis_sezonu')['consumption'].mean()
            kis_sezonlari = sorted(kis_sezon_avg.index)
            
            if len(kis_sezonlari) >= 2:
                ilk_kis_sezonlari = kis_sezon_avg[kis_sezonlari[:len(kis_sezonlari)//2]]
                son_kis_sezonlari = kis_sezon_avg[kis_sezonlari[len(kis_sezonlari)//2:]]
                
                ilk_kis_ort = ilk_kis_sezonlari.mean()
                son_kis_ort = son_kis_sezonlari.mean()
        
        # ===========================================
        # KAÃ‡AK SKORLAMA VE ANOMALÄ° TESPÄ°TÄ°
        # ===========================================
        
        # SENARYO 1: Normal dÃ¶nem var + Sonra ani dÃ¼ÅŸÃ¼ÅŸ
        if len(normal_months) >= min_normal_ay:
            normal_avg = normal_months['consumption'].mean()
            
            # Son aylar dÃ¼ÅŸÃ¼k mÃ¼?
            son_6_ay = cons_df.tail(6)
            son_6_ay_avg = son_6_ay['consumption'].mean()
            
            if son_6_ay_avg < normal_avg * (1 - ani_dusus_orani/100):
                dusus_orani = ((normal_avg - son_6_ay_avg) / normal_avg) * 100
                
                if son_6_ay_avg == 0:
                    anomalies.append(f"ğŸš¨ KRÄ°TÄ°K KAÃ‡AK: TÃ¼ketim SIFIRA dÃ¼ÅŸtÃ¼ (Normal: {normal_avg:.1f} â†’ Son: 0)")
                    leak_score += 50
                elif son_6_ay_avg < 10:
                    anomalies.append(f"ğŸš¨ KRÄ°TÄ°K KAÃ‡AK: Neredeyse sÄ±fÄ±r tÃ¼ketim (Normal: {normal_avg:.1f} â†’ Son: {son_6_ay_avg:.1f})")
                    leak_score += 45
                else:
                    anomalies.append(f"âš ï¸ ÅÃœPHELÄ° DÃœÅÃœÅ: %{dusus_orani:.0f} dÃ¼ÅŸÃ¼ÅŸ (Normal: {normal_avg:.1f} â†’ Son: {son_6_ay_avg:.1f})")
                    leak_score += 30
        
        # SENARYO 2: KÄ±ÅŸ sezonlarÄ± arasÄ±nda dramatik dÃ¼ÅŸÃ¼ÅŸ
        if len(kis_aylari) > 0 and len(kis_sezonlari) >= 2:
            if ilk_kis_ort >= normal_kis_esik and son_kis_ort < dusuk_tuketim_esik:
                dusus = ((ilk_kis_ort - son_kis_ort) / ilk_kis_ort) * 100
                
                ilk_sezon_str = ', '.join(kis_sezonlari[:len(kis_sezonlari)//2])
                son_sezon_str = ', '.join(kis_sezonlari[len(kis_sezonlari)//2:])
                
                if son_kis_ort == 0:
                    anomalies.append(f"ğŸš¨ KIÅ KAÃ‡AÄI: {ilk_sezon_str} ({ilk_kis_ort:.1f}) â†’ {son_sezon_str} (0)")
                    leak_score += 40
                else:
                    anomalies.append(f"âš ï¸ KIÅ DÃœÅÃœÅÃœ: {ilk_sezon_str} ({ilk_kis_ort:.1f}) â†’ {son_sezon_str} ({son_kis_ort:.1f}), %{dusus:.0f} dÃ¼ÅŸÃ¼ÅŸ")
                    leak_score += 25
        
        # SENARYO 3: Ä°lk yarÄ± vs Ä°kinci yarÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
        if first_half_avg >= normal_kis_esik and second_half_avg < dusuk_tuketim_esik:
            dusus = ((first_half_avg - second_half_avg) / first_half_avg) * 100
            anomalies.append(f"ğŸ“‰ DÃ–NEMSEL DÃœÅÃœÅ: Ä°lk dÃ¶nem {first_half_avg:.1f} â†’ Son dÃ¶nem {second_half_avg:.1f} (%{dusus:.0f})")
            leak_score += 20
        
        # SENARYO 4: SÃ¼rekli sÄ±fÄ±r veya Ã§ok dÃ¼ÅŸÃ¼k tÃ¼ketim
        if len(zero_months) >= 6:
            anomalies.append(f"â›” SÃœREKLÄ° SIFIR: {len(zero_months)} ay sÄ±fÄ±r tÃ¼ketim")
            leak_score += 35
        elif len(low_months) >= 8:
            anomalies.append(f"ğŸ“Š SÃœREKLÄ° DÃœÅÃœK: {len(low_months)} ay dÃ¼ÅŸÃ¼k tÃ¼ketim (<{dusuk_tuketim_esik})")
            leak_score += 15
        
        # SENARYO 5: KÄ±ÅŸ-Yaz farkÄ± yok (doÄŸal olmayan)
        kis_avg = cons_df[cons_df['season'] == 'KÄ±ÅŸ']['consumption'].mean()
        yaz_avg = cons_df[cons_df['season'] == 'Yaz']['consumption'].mean()
        
        if kis_avg > 0 and yaz_avg > 0:
            if abs(kis_avg - yaz_avg) < 15 and kis_avg < dusuk_tuketim_esik:
                anomalies.append(f"ğŸ” DOÄAL OLMAYAN: KÄ±ÅŸ-yaz farkÄ± yok (KÄ±ÅŸ: {kis_avg:.1f}, Yaz: {yaz_avg:.1f})")
                leak_score += 10
        
        # ===========================================
        # KAÃ‡AK SEVÄ°YESÄ° BELÄ°RLEME
        # ===========================================
        
        if leak_score >= 40:
            leak_level = "ğŸš¨ YÃœksek Riskli"
            suspicion = "YÃ¼ksek Riskli KaÃ§ak"
        elif leak_score >= 20:
            leak_level = "âš ï¸ Orta Riskli"
            suspicion = "Orta Riskli KaÃ§ak"
        elif leak_score > 0:
            leak_level = "ğŸ” DÃ¼ÅŸÃ¼k Riskli"
            suspicion = "DÃ¼ÅŸÃ¼k Riskli"
        else:
            leak_level = "âœ… Normal"
            suspicion = "Normal"
        
        # Trend analizi
        if len(cons_df) >= 12:
            ilk_12 = cons_df.head(12)['consumption'].mean()
            son_12 = cons_df.tail(12)['consumption'].mean()
            
            if ilk_12 >= normal_kis_esik:
                if son_12 == 0:
                    trend = "SIFIRA DÃœÅTÃœ"
                elif son_12 < ilk_12 * 0.2:
                    trend = "Kritik DÃ¼ÅŸÃ¼ÅŸ (%80+)"
                elif son_12 < ilk_12 * 0.5:
                    trend = "Ciddi DÃ¼ÅŸÃ¼ÅŸ"
                elif son_12 < ilk_12 * 0.8:
                    trend = "AzalÄ±ÅŸ Trendi"
                else:
                    trend = "Stabil"
            else:
                trend = "DÃ¼ÅŸÃ¼k BaÅŸlangÄ±Ã§"
        else:
            trend = "Yetersiz Veri"
        
        # SonuÃ§larÄ± kaydet
        results.append({
            'tesisat_no': tesisat_no,
            'bina_no': bina_no,
            'ortalama_tuketim': cons_df['consumption'].mean(),
            'kis_tuketim': kis_avg if kis_avg > 0 else 0,
            'yaz_tuketim': yaz_avg if yaz_avg > 0 else 0,
            'ilk_donem_ort': first_half_avg,
            'son_donem_ort': second_half_avg,
            'normal_ay_sayisi': len(normal_months),
            'dusuk_ay_sayisi': len(low_months),
            'sifir_ay_sayisi': len(zero_months),
            'leak_score': leak_score,
            'leak_level': leak_level,
            'suspicion': suspicion,
            'trend': trend,
            'anomali_sayisi': len(anomalies),
            'anomaliler': ' | '.join(anomalies) if anomalies else 'Anomali yok'
        })
    
    return pd.DataFrame(results)

def create_visualizations(results_df):
    """GÃ¶rselleÅŸtirmeler"""
    
    col1, col2 = st.columns(2)
    
    with col1:
        # KaÃ§ak seviyesi daÄŸÄ±lÄ±mÄ±
        level_counts = results_df['leak_level'].value_counts()
        fig1 = px.pie(
            values=level_counts.values,
            names=level_counts.index,
            title="KaÃ§ak Risk Seviyesi DaÄŸÄ±lÄ±mÄ±",
            color_discrete_sequence=['#00D9FF', '#FFD700', '#FF6B6B', '#C70039']
        )
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # Anomali sayÄ±sÄ± daÄŸÄ±lÄ±mÄ±
        fig2 = px.histogram(
            results_df,
            x='anomali_sayisi',
            title="Anomali SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±",
            color='suspicion',
            color_discrete_map={
                'Normal': '#4ECDC4',
                'DÃ¼ÅŸÃ¼k Riskli': '#FFE66D',
                'Orta Riskli KaÃ§ak': '#FF6B6B',
                'YÃ¼ksek Riskli KaÃ§ak': '#C70039'
            }
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    # KaÃ§ak skoru daÄŸÄ±lÄ±mÄ±
    fig3 = px.box(
        results_df,
        x='suspicion',
        y='leak_score',
        title="KaÃ§ak Skoru DaÄŸÄ±lÄ±mÄ± (Risk Seviyesine GÃ¶re)",
        color='suspicion',
        color_discrete_map={
            'Normal': '#4ECDC4',
            'DÃ¼ÅŸÃ¼k Riskli': '#FFE66D',
            'Orta Riskli KaÃ§ak': '#FF6B6B',
            'YÃ¼ksek Riskli KaÃ§ak': '#C70039'
        }
    )
    st.plotly_chart(fig3, use_container_width=True)
    
    # Ä°lk dÃ¶nem vs Son dÃ¶nem karÅŸÄ±laÅŸtÄ±rmasÄ±
    fig4 = px.scatter(
        results_df,
        x='ilk_donem_ort',
        y='son_donem_ort',
        color='suspicion',
        size='leak_score',
        title="Ä°lk DÃ¶nem vs Son DÃ¶nem TÃ¼ketim KarÅŸÄ±laÅŸtÄ±rmasÄ±",
        labels={'ilk_donem_ort': 'Ä°lk DÃ¶nem Ortalama', 'son_donem_ort': 'Son DÃ¶nem Ortalama'},
        color_discrete_map={
            'Normal': '#4ECDC4',
            'DÃ¼ÅŸÃ¼k Riskli': '#FFE66D',
            'Orta Riskli KaÃ§ak': '#FF6B6B',
            'YÃ¼ksek Riskli KaÃ§ak': '#C70039'
        },
        hover_data=['tesisat_no', 'leak_score', 'trend']
    )
    
    # EÅŸitlik Ã§izgisi
    max_val = max(results_df['ilk_donem_ort'].max(), results_df['son_donem_ort'].max())
    fig4.add_trace(go.Scatter(
        x=[0, max_val],
        y=[0, max_val],
        mode='lines',
        name='EÅŸitlik Ã‡izgisi',
        line=dict(dash='dash', color='gray')
    ))
    
    st.plotly_chart(fig4, use_container_width=True)

# Ana uygulama
if uploaded_file is not None:
    df = load_data(uploaded_file)
    
    if df is not None:
        st.success("âœ… Dosya baÅŸarÄ±yla yÃ¼klendi!")
        
        st.subheader("ğŸ“Š Veri Ã–nizleme")
        st.dataframe(df.head())
        
        st.subheader("ğŸ”§ SÃ¼tun SeÃ§imi")
        
        date_columns, other_columns = parse_date_columns(df)
        
        col1, col2 = st.columns(2)
        
        with col1:
            tesisat_col = st.selectbox("Tesisat NumarasÄ± SÃ¼tunu", options=other_columns)
        
        with col2:
            bina_col = st.selectbox("Bina NumarasÄ± SÃ¼tunu", options=other_columns)
        
        st.write(f"**Tespit edilen tarih sÃ¼tunlarÄ±:** {len(date_columns)} adet")
        if date_columns:
            st.write(f"Tarih aralÄ±ÄŸÄ±: {date_columns[0]} - {date_columns[-1]}")
        
        if st.button("ğŸ” KaÃ§ak Analizi BaÅŸlat", type="primary"):
            with st.spinner("Analiz yapÄ±lÄ±yor..."):
                results_df = analyze_leak_patterns(df, date_columns, tesisat_col, bina_col)
                
                # Ã–zet istatistikler
                st.subheader("ğŸ“ˆ Analiz SonuÃ§larÄ±")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Toplam Tesisat", len(results_df))
                
                with col2:
                    high_risk = len(results_df[results_df['suspicion'] == 'YÃ¼ksek Riskli KaÃ§ak'])
                    st.metric("YÃ¼ksek Riskli", high_risk, delta=f"%{(high_risk/len(results_df)*100):.1f}")
                
                with col3:
                    medium_risk = len(results_df[results_df['suspicion'] == 'Orta Riskli KaÃ§ak'])
                    st.metric("Orta Riskli", medium_risk)
                
                with col4:
                    total_anomalies = results_df['anomali_sayisi'].sum()
                    st.metric("Toplam Anomali", total_anomalies)
                
                # GÃ¶rselleÅŸtirmeler
                st.subheader("ğŸ“Š GÃ¶rselleÅŸtirmeler")
                create_visualizations(results_df)
                
                # YÃ¼ksek riskli tesisatlar
                st.subheader("ğŸš¨ YÃ¼ksek Riskli KaÃ§ak ÅÃ¼pheleri")
                high_risk_df = results_df[results_df['suspicion'] == 'YÃ¼ksek Riskli KaÃ§ak'].copy()
                
                if not high_risk_df.empty:
                    high_risk_df = high_risk_df.sort_values('leak_score', ascending=False)
                    
                    display_cols = ['tesisat_no', 'bina_no', 'leak_score', 'ilk_donem_ort', 
                                   'son_donem_ort', 'trend', 'anomali_sayisi', 'anomaliler']
                    
                    display_df = high_risk_df[display_cols].copy()
                    display_df.columns = ['Tesisat No', 'Bina No', 'KaÃ§ak Skoru', 
                                         'Ä°lk DÃ¶nem Ort.', 'Son DÃ¶nem Ort.', 'Trend',
                                         'Anomali SayÄ±sÄ±', 'Tespit Edilen Anomaliler']
                    
                    for col in ['KaÃ§ak Skoru', 'Ä°lk DÃ¶nem Ort.', 'Son DÃ¶nem Ort.']:
                        display_df[col] = display_df[col].round(1)
                    
                    st.dataframe(display_df, use_container_width=True, hide_index=True)
                    
                    # Excel indirme
                    import io
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                        display_df.to_excel(writer, index=False, sheet_name="YÃ¼ksek Riskli")
                    output.seek(0)
                    
                    st.download_button(
                        label="ğŸ“¥ YÃ¼ksek Riskli TesisatlarÄ± Ä°ndir (EXCEL)",
                        data=output,
                        file_name="yuksek_riskli_kacaklar.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.success("ğŸ‰ YÃ¼ksek riskli kaÃ§ak tespit edilmedi!")
                
                # TÃ¼m sonuÃ§lar
                st.subheader("ğŸ“‹ TÃ¼m SonuÃ§lar")
                
                risk_filter = st.selectbox(
                    "Risk Seviyesi Filtrele",
                    options=['TÃ¼mÃ¼'] + results_df['suspicion'].unique().tolist()
                )
                
                filtered_df = results_df.copy()
                if risk_filter != 'TÃ¼mÃ¼':
                    filtered_df = filtered_df[filtered_df['suspicion'] == risk_filter]
                
                if not filtered_df.empty:
                    display_cols = ['tesisat_no', 'bina_no', 'leak_level', 'leak_score',
                                   'trend', 'anomali_sayisi', 'anomaliler']
                    
                    all_display = filtered_df[display_cols].copy()
                    all_display.columns = ['Tesisat No', 'Bina No', 'Risk Seviyesi', 'KaÃ§ak Skoru',
                                          'Trend', 'Anomali SayÄ±sÄ±', 'Anomaliler']
                    
                    all_display['KaÃ§ak Skoru'] = all_display['KaÃ§ak Skoru'].round(1)
                    
                    st.dataframe(all_display, use_container_width=True, hide_index=True)

else:
    st.info("ğŸ‘ˆ LÃ¼tfen sol panelden bir dosya yÃ¼kleyin")
    
    st.subheader("ğŸ“„ Beklenen Dosya FormatÄ±")
    
    example_data = {
        'tesisat_no': ['T001', 'T002', 'T003'],
        'bina_no': ['B001', 'B001', 'B002'],
        '2018/1': [150, 145, 160],
        '2018/2': [140, 135, 150],
        '2022/11': [145, 140, 155],
        '2022/12': [155, 150, 165],
        '2023/1': [10, 5, 8],
        '2023/2': [8, 3, 6]
    }
    
    st.dataframe(pd.DataFrame(example_data), use_container_width=True)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ¯ KaÃ§ak Tespit YÃ¶ntemi")
st.sidebar.markdown(f"""
**Analiz Kriterleri:**
- Normal kÄ±ÅŸ: â‰¥ {normal_kis_esik} mÂ³/ay
- DÃ¼ÅŸÃ¼k tÃ¼ketim: < {dusuk_tuketim_esik} mÂ³/ay
- Kritik dÃ¼ÅŸÃ¼ÅŸ: %{ani_dusus_orani}+ dÃ¼ÅŸÃ¼ÅŸ

**Tespit SenaryolarÄ±:**
1. âœ… Normal dÃ¶nem + Ani dÃ¼ÅŸÃ¼ÅŸ
2. â„ï¸ KÄ±ÅŸ sezonlarÄ± arasÄ± dÃ¼ÅŸÃ¼ÅŸ
3. ğŸ“Š DÃ¶nemsel analiz
4. â›” SÃ¼rekli sÄ±fÄ±r/dÃ¼ÅŸÃ¼k
5. ğŸ” KÄ±ÅŸ-yaz farkÄ± analizi

**Skorlama:**
- 40+ puan: YÃ¼ksek Risk
- 20-39: Orta Risk
- 1-19: DÃ¼ÅŸÃ¼k Risk
- 0: Normal
""")
