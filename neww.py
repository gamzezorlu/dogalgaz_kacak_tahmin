import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="DoÄŸalgaz KaÃ§ak Tespit Sistemi",
    page_icon="ğŸ”¥",
    layout="wide"
)

st.title("ğŸ”¥ DoÄŸalgaz KaÃ§ak Tespit Sistemi - GeliÅŸmiÅŸ v3")
st.markdown("---")

# Yan panel
st.sidebar.header("ğŸ“ Dosya YÃ¼kleme")
uploaded_file = st.sidebar.file_uploader(
    "CSV veya Excel dosyasÄ± seÃ§in",
    type=['csv', 'xlsx', 'xls']
)

# Parametreler
st.sidebar.header("âš™ï¸ Tespit Parametreleri")

normal_kis_esik = st.sidebar.slider(
    "Normal kÄ±ÅŸ tÃ¼ketimi eÅŸiÄŸi (mÂ³/ay)",
    min_value=30, max_value=150, value=60,
    help="Bu deÄŸerin Ã¼zerindeki kÄ±ÅŸ tÃ¼ketimi 'normal' kabul edilir"
)

dusuk_tuketim_esik = st.sidebar.slider(
    "DÃ¼ÅŸÃ¼k tÃ¼ketim eÅŸiÄŸi (mÂ³/ay)",
    min_value=5, max_value=50, value=25,
    help="Bu deÄŸerin altÄ±ndaki tÃ¼ketim 'ÅŸÃ¼pheli' kabul edilir"
)

min_dusus_orani = st.sidebar.slider(
    "Minimum dÃ¼ÅŸÃ¼ÅŸ oranÄ± (%)",
    min_value=30, max_value=80, value=50,
    help="Bu oranda dÃ¼ÅŸÃ¼ÅŸ kaÃ§ak ÅŸÃ¼phesi oluÅŸturur"
)

agresif_mod = st.sidebar.checkbox(
    "ğŸ”¥ Agresif Tespit Modu",
    value=True,
    help="Daha fazla kaÃ§ak tespit eder, ancak yanlÄ±ÅŸ pozitif artabilir"
)

def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        st.error(f"Dosya yÃ¼kleme hatasÄ±: {str(e)}")
        return None

def parse_date_columns(df):
    date_columns = []
    other_columns = []
    
    for col in df.columns:
        if isinstance(col, str) and '/' in col:
            try:
                parts = col.split('/')
                year = parts[0]
                month = parts[1] if len(parts) > 1 else '1'
                if len(year) == 4 and 1 <= int(month) <= 12:
                    date_columns.append(col)
                else:
                    other_columns.append(col)
            except:
                other_columns.append(col)
        else:
            other_columns.append(col)
    
    return sorted(date_columns), other_columns

def get_season(month):
    if month in [12, 1, 2]:
        return "KÄ±ÅŸ"
    elif month in [3, 4, 5]:
        return "Ä°lkbahar"
    elif month in [6, 7, 8]:
        return "Yaz"
    else:
        return "Sonbahar"

def detect_leak_comprehensive(df, date_columns, tesisat_col, bina_col, params):
    """KAPSAMLI KAÃ‡AK TESPÄ°T SÄ°STEMÄ° - TÃœM PATERNLER"""
    results = []
    
    for idx, row in df.iterrows():
        tesisat_no = row[tesisat_col]
        bina_no = row[bina_col]
        
        # TÃ¼m aylÄ±k verileri topla
        monthly_data = []
        for date_col in date_columns:
            try:
                value = row[date_col]
                if pd.notna(value):
                    year, month = date_col.split('/')
                    monthly_data.append({
                        'year': int(year),
                        'month': int(month),
                        'consumption': float(value),
                        'season': get_season(int(month)),
                        'date_str': date_col,
                        'date_col': date_col
                    })
            except:
                continue
        
        if len(monthly_data) < 4:
            continue
        
        cons_df = pd.DataFrame(monthly_data)
        cons_df = cons_df.sort_values(['year', 'month']).reset_index(drop=True)
        
        # ===========================================
        # VERÄ° Ã–N ANALÄ°Z
        # ===========================================
        
        total_months = len(cons_df)
        avg_consumption = cons_df['consumption'].mean()
        median_consumption = cons_df['consumption'].median()
        max_consumption = cons_df['consumption'].max()
        min_consumption = cons_df['consumption'].min()
        
        # SÄ±fÄ±r olmayan deÄŸerler
        non_zero = cons_df[cons_df['consumption'] > 0]
        if len(non_zero) > 0:
            avg_non_zero = non_zero['consumption'].mean()
            median_non_zero = non_zero['consumption'].median()
        else:
            avg_non_zero = 0
            median_non_zero = 0
        
        # ===========================================
        # KAÃ‡AK TESPÄ°T MANTIKLARI (12 FARKLI YÃ–NTEM)
        # ===========================================
        
        anomalies = []
        leak_score = 0
        detected_patterns = []
        
        # ========== YÃ–NTEM 1: ZAMAN DÄ°LÄ°MLERÄ° ANALÄ°ZÄ° ==========
        # Her 6 aylÄ±k dilimlere bÃ¶l ve karÅŸÄ±laÅŸtÄ±r
        if total_months >= 12:
            chunks = []
            for i in range(0, total_months, 6):
                chunk = cons_df.iloc[i:i+6]
                if len(chunk) >= 3:
                    chunks.append({
                        'start': i,
                        'end': i+len(chunk),
                        'avg': chunk['consumption'].mean(),
                        'median': chunk['consumption'].median(),
                        'max': chunk['consumption'].max(),
                        'period': f"{chunk.iloc[0]['date_str']} - {chunk.iloc[-1]['date_str']}"
                    })
            
            # Ä°lk dilim ile sonraki dilimleri karÅŸÄ±laÅŸtÄ±r
            if len(chunks) >= 2:
                first_chunk = chunks[0]
                
                for i, chunk in enumerate(chunks[1:], 1):
                    if first_chunk['avg'] >= params['normal_kis_esik']:
                        dusus = ((first_chunk['avg'] - chunk['avg']) / first_chunk['avg']) * 100
                        
                        if dusus >= params['min_dusus_orani']:
                            if chunk['avg'] == 0:
                                anomalies.append(f"ğŸš¨ DÃ–NEM-{i}: SÄ±fÄ±ra dÃ¼ÅŸtÃ¼ ({first_chunk['period']}: {first_chunk['avg']:.1f} â†’ {chunk['period']}: 0)")
                                leak_score += 50
                                detected_patterns.append("SÄ±fÄ±ra DÃ¼ÅŸÃ¼ÅŸ")
                            elif chunk['avg'] < params['dusuk_tuketim_esik']:
                                anomalies.append(f"âš ï¸ DÃ–NEM-{i}: Kritik dÃ¼ÅŸÃ¼ÅŸ ({first_chunk['avg']:.1f} â†’ {chunk['avg']:.1f}, %{dusus:.0f})")
                                leak_score += 40
                                detected_patterns.append("Kritik DÃ¼ÅŸÃ¼ÅŸ")
                            else:
                                anomalies.append(f"ğŸ“‰ DÃ–NEM-{i}: Ciddi dÃ¼ÅŸÃ¼ÅŸ (%{dusus:.0f})")
                                leak_score += 25
                                detected_patterns.append("Ciddi DÃ¼ÅŸÃ¼ÅŸ")
        
        # ========== YÃ–NTEM 2: YILLIK KARÅILAÅTIRMA ==========
        yearly_avg = cons_df.groupby('year')['consumption'].mean()
        years = sorted(yearly_avg.index)
        
        if len(years) >= 2:
            first_year_avg = yearly_avg[years[0]]
            last_year_avg = yearly_avg[years[-1]]
            
            if first_year_avg >= params['normal_kis_esik']:
                year_dusus = ((first_year_avg - last_year_avg) / first_year_avg) * 100
                
                if year_dusus >= params['min_dusus_orani']:
                    anomalies.append(f"ğŸ“… YILLIK: {years[0]} ({first_year_avg:.1f}) â†’ {years[-1]} ({last_year_avg:.1f}), %{year_dusus:.0f} dÃ¼ÅŸÃ¼ÅŸ")
                    leak_score += 30
                    detected_patterns.append("YÄ±llÄ±k DÃ¼ÅŸÃ¼ÅŸ")
        
        # ========== YÃ–NTEM 3: KIÅ AYLARINDA Ã–ZEL ANALÄ°Z ==========
        kis_data = cons_df[cons_df['season'] == 'KÄ±ÅŸ'].copy()
        
        if len(kis_data) >= 3:
            # Her kÄ±ÅŸ ayÄ±nÄ± ayrÄ± deÄŸerlendir
            kis_values = kis_data['consumption'].values
            kis_dates = kis_data['date_str'].values
            
            # Ä°lk kÄ±ÅŸ aylarÄ± ortalamasÄ±
            first_kis = kis_values[:len(kis_values)//2]
            last_kis = kis_values[len(kis_values)//2:]
            
            if len(first_kis) > 0 and len(last_kis) > 0:
                first_kis_avg = np.mean(first_kis)
                last_kis_avg = np.mean(last_kis)
                
                if first_kis_avg >= params['normal_kis_esik']:
                    kis_dusus = ((first_kis_avg - last_kis_avg) / first_kis_avg) * 100
                    
                    if kis_dusus >= params['min_dusus_orani']:
                        anomalies.append(f"â„ï¸ KIÅ: Ä°lk kÄ±ÅŸlar ({first_kis_avg:.1f}) â†’ Son kÄ±ÅŸlar ({last_kis_avg:.1f}), %{kis_dusus:.0f} dÃ¼ÅŸÃ¼ÅŸ")
                        leak_score += 35
                        detected_patterns.append("KÄ±ÅŸ DÃ¼ÅŸÃ¼ÅŸÃ¼")
        
        # ========== YÃ–NTEM 4: HAREKET EDEN ORTALAMA ==========
        # Son 3 ay vs Ã–nceki 3 ay karÅŸÄ±laÅŸtÄ±rmasÄ± (kayan pencere)
        if total_months >= 12:
            window = 3
            max_drop = 0
            drop_location = None
            
            for i in range(window, total_months - window):
                before_avg = cons_df.iloc[i-window:i]['consumption'].mean()
                after_avg = cons_df.iloc[i:i+window]['consumption'].mean()
                
                if before_avg >= params['normal_kis_esik']:
                    drop = ((before_avg - after_avg) / before_avg) * 100
                    if drop > max_drop:
                        max_drop = drop
                        drop_location = (i-window, i+window)
            
            if max_drop >= params['min_dusus_orani']:
                start_date = cons_df.iloc[drop_location[0]]['date_str']
                end_date = cons_df.iloc[drop_location[1]-1]['date_str']
                anomalies.append(f"ğŸ“Š KAYAN: {start_date} civarÄ±nda %{max_drop:.0f} dÃ¼ÅŸÃ¼ÅŸ tespit edildi")
                leak_score += 20
                detected_patterns.append("Ani DeÄŸiÅŸim")
        
        # ========== YÃ–NTEM 5: SÃœREKLÄ° DÃœÅÃœK TÃœKETÄ°M ==========
        low_count = len(cons_df[cons_df['consumption'] < params['dusuk_tuketim_esik']])
        zero_count = len(cons_df[cons_df['consumption'] == 0])
        
        if low_count >= total_months * 0.5:  # YarÄ±sÄ±ndan fazlasÄ± dÃ¼ÅŸÃ¼k
            anomalies.append(f"ğŸ“‰ SÃœREKLÄ° DÃœÅÃœK: {low_count}/{total_months} ay dÃ¼ÅŸÃ¼k tÃ¼ketim")
            leak_score += 30
            detected_patterns.append("SÃ¼rekli DÃ¼ÅŸÃ¼k")
        
        if zero_count >= 4:
            anomalies.append(f"â›” SIFIR: {zero_count} ay sÄ±fÄ±r tÃ¼ketim")
            leak_score += 25
            detected_patterns.append("SÄ±fÄ±r Aylar")
        
        # ========== YÃ–NTEM 6: STANDART SAPMA ANALÄ°ZÄ° ==========
        if len(non_zero) > 0:
            std = non_zero['consumption'].std()
            cv = (std / avg_non_zero) if avg_non_zero > 0 else 0  # Varyasyon katsayÄ±sÄ±
            
            # YÃ¼ksek varyasyon + dÃ¼ÅŸÃ¼k son deÄŸerler = ÅŸÃ¼pheli
            if cv > 0.8:  # YÃ¼ksek varyasyon
                son_5 = cons_df.tail(5)['consumption'].mean()
                if son_5 < avg_non_zero * 0.3:
                    anomalies.append(f"ğŸ“ˆ VARYASYON: YÃ¼ksek dalgalanma ve dÃ¼ÅŸÃ¼k son deÄŸerler")
                    leak_score += 15
                    detected_patterns.append("YÃ¼ksek Varyasyon")
        
        # ========== YÃ–NTEM 7: MEVSÄ°MSEL PATTERN ==========
        seasonal_avg = cons_df.groupby('season')['consumption'].mean()
        
        if 'KÄ±ÅŸ' in seasonal_avg.index and 'Yaz' in seasonal_avg.index:
            kis_avg = seasonal_avg['KÄ±ÅŸ']
            yaz_avg = seasonal_avg['Yaz']
            
            # KÄ±ÅŸ yaz farkÄ± Ã§ok az ve her ikisi de dÃ¼ÅŸÃ¼k
            if kis_avg < params['dusuk_tuketim_esik'] and abs(kis_avg - yaz_avg) < 10:
                anomalies.append(f"ğŸ” MEVSÄ°M: KÄ±ÅŸ-yaz farkÄ± yok ve dÃ¼ÅŸÃ¼k (KÄ±ÅŸ: {kis_avg:.1f}, Yaz: {yaz_avg:.1f})")
                leak_score += 20
                detected_patterns.append("Mevsim Anomalisi")
        
        # ========== YÃ–NTEM 8: TOPLAM TÃœKETÄ°M ANALÄ°ZÄ° ==========
        total_consumption = cons_df['consumption'].sum()
        expected_min = total_months * 30  # Minimum beklenen (30 mÂ³/ay)
        
        if total_consumption < expected_min:
            anomalies.append(f"ğŸ’° TOPLAM DÃœÅÃœK: {total_consumption:.1f} mÂ³ (Beklenen min: {expected_min})")
            leak_score += 15
            detected_patterns.append("Toplam DÃ¼ÅŸÃ¼k")
        
        # ========== YÃ–NTEM 9: SON AYLARA Ã–ZEL BAKIM ==========
        if total_months >= 6:
            son_6 = cons_df.tail(6)
            son_3 = cons_df.tail(3)
            
            son_6_avg = son_6['consumption'].mean()
            son_3_avg = son_3['consumption'].mean()
            
            # Son 6 ay Ã§ok dÃ¼ÅŸÃ¼k
            if avg_non_zero >= params['normal_kis_esik'] and son_6_avg < params['dusuk_tuketim_esik']:
                anomalies.append(f"ğŸ”´ SON 6 AY: Ã‡ok dÃ¼ÅŸÃ¼k tÃ¼ketim ({son_6_avg:.1f})")
                leak_score += 35
                detected_patterns.append("Son Aylar DÃ¼ÅŸÃ¼k")
            
            # Son 3 ay sÄ±fÄ±r veya neredeyse sÄ±fÄ±r
            if son_3_avg < 5:
                anomalies.append(f"ğŸš¨ SON 3 AY: Neredeyse sÄ±fÄ±r ({son_3_avg:.1f})")
                leak_score += 40
                detected_patterns.append("Son Aylar SÄ±fÄ±r")
        
        # ========== YÃ–NTEM 10: TREND ANALÄ°ZÄ° (Linear Regression) ==========
        if total_months >= 12:
            x = np.arange(len(cons_df))
            y = cons_df['consumption'].values
            
            # Basit doÄŸrusal trend
            if len(x) > 0 and np.std(y) > 0:
                z = np.polyfit(x, y, 1)
                slope = z[0]
                
                # Negatif trend (dÃ¼ÅŸÃ¼ÅŸ) ve yÃ¼ksek baÅŸlangÄ±Ã§
                if slope < -2 and cons_df.head(6)['consumption'].mean() >= params['normal_kis_esik']:
                    anomalies.append(f"ğŸ“‰ TREND: SÃ¼rekli azalÄ±ÅŸ trendi (eÄŸim: {slope:.2f})")
                    leak_score += 20
                    detected_patterns.append("Negatif Trend")
        
        # ========== YÃ–NTEM 11: BÄ°NA ORTALAMASIYLA KARÅILAÅTIRMA ==========
        bina_tesisatlari = df[df[bina_col] == bina_no]
        
        if len(bina_tesisatlari) > 2:
            bina_averages = []
            
            for _, other_row in bina_tesisatlari.iterrows():
                if other_row[tesisat_col] == tesisat_no:
                    continue
                
                other_total = 0
                other_count = 0
                
                for date_col in date_columns:
                    try:
                        val = other_row[date_col]
                        if pd.notna(val) and val > 0:
                            other_total += float(val)
                            other_count += 1
                    except:
                        continue
                
                if other_count > 0:
                    bina_averages.append(other_total / other_count)
            
            if len(bina_averages) > 0:
                bina_avg = np.mean(bina_averages)
                
                if avg_non_zero > 0 and bina_avg > params['normal_kis_esik']:
                    fark = ((bina_avg - avg_non_zero) / bina_avg) * 100
                    
                    if fark >= 60:
                        anomalies.append(f"ğŸ¢ BÄ°NA: Bina ortalamasÄ±ndan %{fark:.0f} dÃ¼ÅŸÃ¼k (Bina: {bina_avg:.1f}, Bu: {avg_non_zero:.1f})")
                        leak_score += 25
                        detected_patterns.append("Bina FarkÄ±")
        
        # ========== YÃ–NTEM 12: AGRESÄ°F MOD - EK KONTROLER ==========
        if params['agresif_mod']:
            # Herhangi bir 12 aylÄ±k dÃ¶nemde ortalama Ã§ok dÃ¼ÅŸÃ¼kse
            if total_months >= 12:
                for i in range(total_months - 11):
                    period_12 = cons_df.iloc[i:i+12]
                    period_avg = period_12['consumption'].mean()
                    
                    if period_avg < params['dusuk_tuketim_esik']:
                        start = period_12.iloc[0]['date_str']
                        end = period_12.iloc[-1]['date_str']
                        anomalies.append(f"ğŸ” AGRESÄ°F: {start} - {end} arasÄ± dÃ¼ÅŸÃ¼k ({period_avg:.1f})")
                        leak_score += 10
                        detected_patterns.append("Agresif Tespit")
                        break  # Bir kez tespit yeterli
        
        # ===========================================
        # KAÃ‡AK SEVÄ°YESÄ° BELÄ°RLEME
        # ===========================================
        
        if leak_score >= 50:
            leak_level = "ğŸš¨ YÃ¼ksek Riskli"
            suspicion = "YÃ¼ksek Riskli KaÃ§ak"
        elif leak_score >= 30:
            leak_level = "âš ï¸ Orta Riskli"
            suspicion = "Orta Riskli KaÃ§ak"
        elif leak_score >= 15:
            leak_level = "ğŸ” DÃ¼ÅŸÃ¼k Riskli"
            suspicion = "DÃ¼ÅŸÃ¼k Riskli"
        else:
            leak_level = "âœ… Normal"
            suspicion = "Normal"
        
        # Trend belirleme
        if len(cons_df) >= 12:
            ilk_12 = cons_df.head(12)['consumption'].mean()
            son_12 = cons_df.tail(12)['consumption'].mean()
            
            if ilk_12 >= params['normal_kis_esik']:
                if son_12 == 0:
                    trend = "SIFIRA DÃœÅTÃœ"
                elif son_12 < ilk_12 * 0.2:
                    trend = "Kritik DÃ¼ÅŸÃ¼ÅŸ (%80+)"
                elif son_12 < ilk_12 * 0.5:
                    trend = "Ciddi DÃ¼ÅŸÃ¼ÅŸ (%50+)"
                elif son_12 < ilk_12 * 0.7:
                    trend = "Orta DÃ¼ÅŸÃ¼ÅŸ"
                elif son_12 < ilk_12 * 0.9:
                    trend = "Hafif DÃ¼ÅŸÃ¼ÅŸ"
                else:
                    trend = "Stabil"
            else:
                trend = "DÃ¼ÅŸÃ¼k BaÅŸlangÄ±Ã§"
        else:
            trend = "Yetersiz Veri"
        
        # ===========================================
        # SONUÃ‡LARI KAYDET
        # ===========================================
        
        results.append({
            'tesisat_no': tesisat_no,
            'bina_no': bina_no,
            'ortalama_tuketim': avg_consumption,
            'median_tuketim': median_consumption,
            'max_tuketim': max_consumption,
            'toplam_tuketim': total_consumption,
            'ay_sayisi': total_months,
            'sifir_ay': zero_count,
            'leak_score': leak_score,
            'leak_level': leak_level,
            'suspicion': suspicion,
            'trend': trend,
            'anomali_sayisi': len(anomalies),
            'tespit_yontemleri': ', '.join(set(detected_patterns)) if detected_patterns else 'Yok',
            'anomaliler': ' | '.join(anomalies) if anomalies else 'Anomali yok'
        })
    
    return pd.DataFrame(results)

def create_visualizations(results_df):
    """GÃ¶rselleÅŸtirmeler"""
    
    col1, col2 = st.columns(2)
    
    with col1:
        # KaÃ§ak seviyesi daÄŸÄ±lÄ±mÄ±
        level_counts = results_df['leak_level'].value_counts()
        fig1 = px.pie(
            values=level_counts.values,
            names=level_counts.index,
            title="KaÃ§ak Risk Seviyesi DaÄŸÄ±lÄ±mÄ±",
            color_discrete_sequence=['#00D9FF', '#FFD700', '#FF6B6B', '#C70039']
        )
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # Tespit yÃ¶ntemi daÄŸÄ±lÄ±mÄ±
        fig2 = px.histogram(
            results_df[results_df['suspicion'] != 'Normal'],
            x='anomali_sayisi',
            title="Tespit Edilen Anomali SayÄ±sÄ± (KaÃ§aklarda)",
            color='suspicion',
            color_discrete_map={
                'DÃ¼ÅŸÃ¼k Riskli': '#FFE66D',
                'Orta Riskli KaÃ§ak': '#FF6B6B',
                'YÃ¼ksek Riskli KaÃ§ak': '#C70039'
            }
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    # KaÃ§ak skoru daÄŸÄ±lÄ±mÄ±
    fig3 = px.box(
        results_df,
        x='suspicion',
        y='leak_score',
        title="KaÃ§ak Skoru DaÄŸÄ±lÄ±mÄ±",
        color='suspicion',
        color_discrete_map={
            'Normal': '#4ECDC4',
            'DÃ¼ÅŸÃ¼k Riskli': '#FFE66D',
            'Orta Riskli KaÃ§ak': '#FF6B6B',
            'YÃ¼ksek Riskli KaÃ§ak': '#C70039'
        }
    )
    st.plotly_chart(fig3, use_container_width=True)
    
    # Ortalama vs Skor scatter
    fig4 = px.scatter(
        results_df,
        x='ortalama_tuketim',
        y='leak_score',
        color='suspicion',
        size='anomali_sayisi',
        title="Ortalama TÃ¼ketim vs KaÃ§ak Skoru",
        hover_data=['tesisat_no', 'trend', 'tespit_yontemleri'],
        color_discrete_map={
            'Normal': '#4ECDC4',
            'DÃ¼ÅŸÃ¼k Riskli': '#FFE66D',
            'Orta Riskli KaÃ§ak': '#FF6B6B',
            'YÃ¼ksek Riskli KaÃ§ak': '#C70039'
        }
    )
    st.plotly_chart(fig4, use_container_width=True)

# Ana uygulama
if uploaded_file is not None:
    df = load_data(uploaded_file)
    
    if df is not None:
        st.success("âœ… Dosya baÅŸarÄ±yla yÃ¼klendi!")
        
        st.subheader("ğŸ“Š Veri Ã–nizleme")
        st.dataframe(df.head())
        
        st.subheader("ğŸ”§ SÃ¼tun SeÃ§imi")
        
        date_columns, other_columns = parse_date_columns(df)
        
        col1, col2 = st.columns(2)
        
        with col1:
            tesisat_col = st.selectbox("Tesisat NumarasÄ± SÃ¼tunu", options=other_columns)
        
        with col2:
            bina_col = st.selectbox("Bina NumarasÄ± SÃ¼tunu", options=other_columns)
        
        st.write(f"**Tespit edilen tarih sÃ¼tunlarÄ±:** {len(date_columns)} adet")
        if date_columns:
            st.write(f"Tarih aralÄ±ÄŸÄ±: {date_columns[0]} - {date_columns[-1]}")
        
        if st.button("ğŸ” KapsamlÄ± KaÃ§ak Analizi BaÅŸlat", type="primary"):
            with st.spinner("12 farklÄ± yÃ¶ntemle analiz yapÄ±lÄ±yor..."):
                
                params = {
                    'normal_kis_esik': normal_kis_esik,
                    'dusuk_tuketim_esik': dusuk_tuketim_esik,
                    'min_dusus_orani': min_dusus_orani,
                    'agresif_mod': agresif_mod
                }
                
                results_df = detect_leak_comprehensive(df, date_columns, tesisat_col, bina_col, params)
                
                # Ã–zet istatistikler
                st.subheader("ğŸ“ˆ Analiz SonuÃ§larÄ±")
                
                col1, col2, col3, col4, col5 = st.columns(5)
                
                with col1:
                    st.metric("Toplam Tesisat", len(results_df))
                
                with col2:
                    high_risk = len(results_df[results_df['suspicion'] == 'YÃ¼ksek Riskli KaÃ§ak'])
                    st.metric("YÃ¼ksek Risk", high_risk, delta=f"%{(high_risk/len(results_df)*100):.1f}")
                
                with col3:
                    medium_risk = len(results_df[results_df['suspicion'] == 'Orta Riskli KaÃ§ak'])
                    st.metric("Orta Risk", medium_risk)
                
                with col4:
                    low_risk = len(results_df[results_df['suspicion'] == 'DÃ¼ÅŸÃ¼k Riskli'])
                    st.metric("DÃ¼ÅŸÃ¼k Risk", low_risk)
                
                with col5:
                    total_suspicious = high_risk + medium_risk + low_risk
                    st.metric("Toplam ÅÃ¼pheli", total_suspicious)
                
                # GÃ¶rselleÅŸtirmeler
                st.subheader("ğŸ“Š GÃ¶rselleÅŸtirmeler")
                create_visualizations(results_df)
                
                # YÃ¼ksek + Orta riskli tesisatlar
                st.subheader("ğŸš¨ YÃ¼ksek ve Orta Riskli KaÃ§ak ÅÃ¼pheleri")
                
                risk_df = results_df[
                    (results_df['suspicion'] == 'YÃ¼ksek Riskli KaÃ§ak') | 
                    (results_df['suspicion'] == 'Orta Riskli KaÃ§ak')
                ].copy()
                
                if not risk_df.empty:
                    risk_df = risk_df.sort_values('leak_score', ascending=False)
                    
                    display_cols = ['tesisat_no', 'bina_no', 'leak_score', 'leak_level',
                                   'ortalama_tuketim', 'trend', 'anomali_sayisi', 
                                   'tespit_yontemleri', 'anomaliler']
                    
                    display_df = risk_df[display_cols].copy()
                    display_df.columns = ['Tesisat No', 'Bina No', 'KaÃ§ak Skoru', 'Risk Seviyesi',
                                         'Ortalama TÃ¼ketim', 'Trend', 'Anomali SayÄ±sÄ±',
                                         'Tespit YÃ¶ntemleri', 'Detaylar']
                    
                    for col in ['KaÃ§ak Skoru', 'Ortalama TÃ¼ketim']:
                        display_df[col] = display_df[col].round(1)
                    
                    st.dataframe(display_df, use_container_width=True, hide_index=True)
                    
                    # Excel indirme
                    import io
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                        display_df.to_excel(writer, index=False, sheet_name="YÃ¼ksek-Orta Risk")
                    output.seek(0)
                    
                    st.download_button(
                        label="ğŸ“¥ YÃ¼ksek ve Orta Riskli TesisatlarÄ± Ä°ndir (EXCEL)",
                        data=output,
                        file_name="yuksek_orta_riskli_kacaklar.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.success("ğŸ‰ YÃ¼ksek/Orta riskli kaÃ§ak tespit edilmedi!")
                
                # TÃ¼m sonuÃ§lar
                st.subheader("ğŸ“‹ TÃ¼m SonuÃ§lar")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    risk_filter = st.selectbox(
                        "Risk Seviyesi Filtrele",
                        options=['TÃ¼mÃ¼'] + sorted(results_df['suspicion'].unique().tolist())
                    )
                
                with col2:
                    bina_filter = st.selectbox(
                        "Bina NumarasÄ± Filtrele",
                        options=['TÃ¼mÃ¼'] + sorted(results_df['bina_no'].unique().tolist())
                    )
                
                filtered_df = results_df.copy()
                
                if risk_filter != 'TÃ¼mÃ¼':
                    filtered_df = filtered_df[filtered_df['suspicion'] == risk_filter]
                
                if bina_filter != 'TÃ¼mÃ¼':
                    filtered_df = filtered_df[filtered_df['bina_no'] == bina_filter]
                
                if not filtered_df.empty:
                    display_cols = ['tesisat_no', 'bina_no', 'leak_level', 'leak_score',
                                   'ortalama_tuketim', 'trend', 'anomali_sayisi', 
                                   'tespit_yontemleri']
                    
                    all_display = filtered_df[display_cols].copy()
                    all_display.columns = ['Tesisat No', 'Bina No', 'Risk Seviyesi', 'KaÃ§ak Skoru',
                                          'Ortalama', 'Trend', 'Anomali', 'YÃ¶ntemler']
                    
                    for col in ['KaÃ§ak Skoru', 'Ortalama']:
                        all_display[col] = all_display[col].round(1)
                    
                    st.dataframe(all_display, use_container_width=True, hide_index=True)
                    
                    # TÃ¼mÃ¼nÃ¼ excel olarak indir
                    output2 = io.BytesIO()
                    with pd.ExcelWriter(output2, engine="xlsxwriter") as writer:
                        all_display.to_excel(writer, index=False, sheet_name="TÃ¼m SonuÃ§lar")
                    output2.seek(0)
                    
                    st.download_button(
                        label="ğŸ“¥ TÃ¼m SonuÃ§larÄ± Ä°ndir (EXCEL)",
                        data=output2,
                        file_name="tum_analiz_sonuclari.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.warning("Filtreye uygun veri bulunamadÄ±.")

else:
    st.info("ğŸ‘ˆ LÃ¼tfen sol panelden bir dosya yÃ¼kleyin")
    
    st.subheader("ğŸ“„ Beklenen Dosya FormatÄ±")
    
    example_data = {
        'tesisat_no': ['T001', 'T002', 'T003'],
        'bina_no': ['B001', 'B001', 'B002'],
        '2018/1': [150, 145, 160],
        '2018/2': [140, 135, 150],
        '2022/11': [145, 140, 155],
        '2022/12': [155, 150, 165],
        '2023/1': [10, 5, 8],
        '2023/2': [8, 3, 6]
    }
    
    st.dataframe(pd.DataFrame(example_data), use_container_width=True)
    
    st.markdown("""
    **Dosya FormatÄ±:**
    - **Tesisat No**: Benzersiz tesisat kimliÄŸi
    - **Bina No**: Bina numarasÄ±
    - **Tarih SÃ¼tunlarÄ±**: YYYY/M formatÄ±nda (2018/1, 2018/2, ...)
    - **DeÄŸerler**: AylÄ±k doÄŸalgaz tÃ¼ketimi (mÂ³)
    """)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ¯ 12 Tespit YÃ¶ntemi")
st.sidebar.markdown(f"""
**Temel EÅŸikler:**
- Normal kÄ±ÅŸ: â‰¥ {normal_kis_esik} mÂ³/ay
- DÃ¼ÅŸÃ¼k tÃ¼ketim: < {dusuk_tuketim_esik} mÂ³/ay
- Minimum dÃ¼ÅŸÃ¼ÅŸ: %{min_dusus_orani}

**Tespit YÃ¶ntemleri:**
1. â±ï¸ Zaman dilimleri (6 aylÄ±k)
2. ğŸ“… YÄ±llÄ±k karÅŸÄ±laÅŸtÄ±rma
3. â„ï¸ KÄ±ÅŸ aylarÄ± analizi
4. ğŸ“Š Kayan pencere (3 aylÄ±k)
5. ğŸ“‰ SÃ¼rekli dÃ¼ÅŸÃ¼k tÃ¼ketim
6. â›” SÄ±fÄ±r aylar
7. ğŸ“ˆ Standart sapma analizi
8. ğŸŒ¡ï¸ Mevsimsel pattern
9. ğŸ’° Toplam tÃ¼ketim
10. ğŸ”´ Son aylar analizi
11. ğŸ“‰ Trend analizi
12. ğŸ¢ Bina karÅŸÄ±laÅŸtÄ±rma

**Skorlama:**
- 50+ puan: ğŸš¨ YÃ¼ksek Risk
- 30-49: âš ï¸ Orta Risk
- 15-29: ğŸ” DÃ¼ÅŸÃ¼k Risk
- 0-14: âœ… Normal
""")
