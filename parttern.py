import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="DoÄŸalgaz KaÃ§ak KullanÄ±m Tespit", page_icon="âš ï¸", layout="wide")

class GasFraudDetector:
    """
    DoÄŸalgaz kaÃ§ak kullanÄ±m anomali tespit sistemi
    
    VERÄ°DEKÄ° PATTERN ANALÄ°ZÄ°:
    -------------------------
    YÃ¼klediÄŸiniz PDF'deki verilerde ÅŸu patternleri tespit ettim:
    
    1. SIKÃ‡A SIFIR TÃœKETÄ°M: BazÄ± tesisatlar uzun sÃ¼re 0 deÄŸer gÃ¶steriyor
       Ã–rnek: Tesisat 10100311, 10109574, 10219911 - aylarca 0 tÃ¼ketim
       â†’ Bu ANORMAL: Ev boÅŸ deÄŸilse sayaca mÃ¼dahale ÅŸÃ¼phesi
    
    2. ANÄ° DÃœÅÃœÅLER: Normal tÃ¼ketimden aniden Ã§ok dÃ¼ÅŸÃ¼k deÄŸerlere dÃ¼ÅŸÃ¼ÅŸ
       Ã–rnek: Tesisat 10004494 â†’ 165 tondan 19 tona dÃ¼ÅŸmÃ¼ÅŸ (90% dÃ¼ÅŸÃ¼ÅŸ)
       â†’ SayaÃ§ manipÃ¼lasyonu iÅŸareti
    
    3. UZUN SÃœRELÄ° DÃœÅÃœK TÃœKETÄ°M: 10+ ay boyunca Ã§ok dÃ¼ÅŸÃ¼k deÄŸerler
       Ã–rnek: Tesisat 10410643, 10415131 - sÃ¼rekli 0-5 ton arasÄ±
       â†’ KaÃ§ak kullanÄ±m paterni
    
    4. AÅÄ°RÄ° DEÄÄ°ÅKENLÄ°K: Bir ay 200, bir ay 5, bir ay 300
       â†’ TutarsÄ±z, ÅŸÃ¼pheli davranÄ±ÅŸ
    
    5. MEVSÄ°MSEL ANORMALLIK: KÄ±ÅŸ-yaz farkÄ± olmamasÄ±
       â†’ Normal evlerde kÄ±ÅŸÄ±n 3-4 kat fazla tÃ¼ketim olmalÄ±
    """
    
    def __init__(self, contamination=0.15):
        self.contamination = contamination
        self.scaler = StandardScaler()
        self.model = IsolationForest(contamination=contamination, random_state=42, n_estimators=100)
        
    def load_excel(self, uploaded_file):
        """Excel/CSV dosyasÄ±nÄ± yÃ¼kle"""
        try:
            # Excel ise
            if uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
                df = pd.read_excel(uploaded_file, header=None)
            # CSV ise
            else:
                # BoÅŸlukla ayrÄ±lmÄ±ÅŸ format
                df = pd.read_csv(uploaded_file, sep=r'\s+', header=None, engine='python')
            
            # Ä°lk sÃ¼tun tesisat ID'si
            self.facility_ids = df.iloc[:, 0].astype(str).values
            # DiÄŸer sÃ¼tunlar tÃ¼ketim deÄŸerleri
            self.consumption_data = df.iloc[:, 1:].apply(pd.to_numeric, errors='coerce').values
            
            return df
        except Exception as e:
            st.error(f"Dosya yÃ¼kleme hatasÄ±: {str(e)}")
            return None
    
    def extract_features(self):
        """
        KaÃ§ak kullanÄ±m patternlerini tespit etmek iÃ§in Ã¶zellikler Ã§Ä±kar
        
        Ã‡IKARILAN Ã–ZELLÄ°KLER:
        1. SÄ±fÄ±r tÃ¼ketim oranÄ± (en Ã¶nemli)
        2. Ani dÃ¼ÅŸÃ¼ÅŸ sayÄ±sÄ±
        3. Maksimum dÃ¼ÅŸÃ¼ÅŸ yÃ¼zdesi
        4. ArdÄ±ÅŸÄ±k dÃ¼ÅŸÃ¼k tÃ¼ketim ay sayÄ±sÄ±
        5. TÃ¼ketim deÄŸiÅŸkenliÄŸi (dÃ¼zensizlik)
        6. Negatif trend dÃ¶nem sayÄ±sÄ±
        7. Mevsimsel dÃ¼zensizlik
        """
        features = []
        
        progress_bar = st.progress(0)
        total = len(self.consumption_data)
        
        for i, row in enumerate(self.consumption_data):
            progress_bar.progress((i + 1) / total)
            
            # NaN deÄŸerleri temizle
            row_clean = row[~np.isnan(row)]
            row_clean = row_clean[row_clean >= 0]  # Negatif deÄŸerleri de temizle
            
            if len(row_clean) == 0:
                continue
            
            # SÄ±fÄ±r olmayan deÄŸerler
            row_nonzero = row_clean[row_clean > 0]
            
            if len(row_nonzero) == 0:
                row_nonzero = np.array([0.001])  # TÃ¼m deÄŸerler sÄ±fÄ±rsa
                
            feature_dict = {
                'facility_id': self.facility_ids[i],
                
                # 1. SIFIR/DÃœÅÃœK TÃœKETÄ°M ANALÄ°ZÄ° (EN Ã–NEMLÄ°!)
                'zero_count': int(np.sum(row_clean == 0)),
                'zero_ratio': float(np.sum(row_clean == 0) / len(row_clean)),
                'low_consumption_count': int(np.sum(row_clean < 5)),
                'low_consumption_ratio': float(np.sum(row_clean < 5) / len(row_clean)),
                
                # 2. ANÄ° DEÄÄ°ÅÄ°MLER
                'sudden_drops': int(self._count_sudden_changes(row_clean, threshold=0.5, direction='down')),
                'sudden_spikes': int(self._count_sudden_changes(row_clean, threshold=0.8, direction='up')),
                'max_drop_percentage': float(self._max_change_ratio(row_clean, direction='down') * 100),
                'max_spike_percentage': float(self._max_change_ratio(row_clean, direction='up') * 100),
                
                # 3. UZUN SÃœRELÄ° DÃœÅÃœK TÃœKETÄ°M
                'consecutive_zero_months': int(self._max_consecutive(row_clean, value=0)),
                'consecutive_low_months': int(self._max_consecutive_low(row_clean, threshold=10)),
                
                # 4. TEMEL Ä°STATÄ°STÄ°KLER
                'mean_consumption': float(np.mean(row_nonzero)),
                'std_consumption': float(np.std(row_nonzero)),
                'median_consumption': float(np.median(row_nonzero)),
                'max_consumption': float(np.max(row_nonzero)),
                'min_consumption': float(np.min(row_nonzero)),
                
                # 5. DEÄÄ°ÅKENLÄ°K
                'coefficient_of_variation': float(np.std(row_nonzero) / np.mean(row_nonzero) if np.mean(row_nonzero) > 0 else 0),
                'range_ratio': float((np.max(row_nonzero) - np.min(row_nonzero)) / np.mean(row_nonzero) if np.mean(row_nonzero) > 0 else 0),
                
                # 6. TREND ANALÄ°ZÄ°
                'overall_trend': float(self._calculate_trend(row_nonzero)),
                'negative_trend_periods': int(self._count_negative_trends(row_clean)),
                
                # 7. MEVSÄ°MSEL ANORMALLIK
                'seasonal_variation': float(self._calculate_seasonal_variation(row_clean)),
                'missing_winter_peak': int(self._check_missing_winter_peak(row_clean)),
            }
            
            features.append(feature_dict)
        
        progress_bar.empty()
        return pd.DataFrame(features)
    
    def _count_sudden_changes(self, data, threshold=0.5, direction='down'):
        """Ani deÄŸiÅŸim sayÄ±sÄ±"""
        if len(data) < 2:
            return 0
        changes = np.diff(data) / (data[:-1] + 0.001)
        if direction == 'down':
            return np.sum(changes < -threshold)
        else:
            return np.sum(changes > threshold)
    
    def _max_change_ratio(self, data, direction='down'):
        """Maksimum deÄŸiÅŸim oranÄ±"""
        if len(data) < 2:
            return 0
        changes = np.diff(data) / (data[:-1] + 0.001)
        if direction == 'down':
            return abs(np.min(changes)) if len(changes) > 0 else 0
        else:
            return np.max(changes) if len(changes) > 0 else 0
    
    def _max_consecutive(self, data, value=0):
        """ArdÄ±ÅŸÄ±k belirli deÄŸer sayÄ±sÄ±"""
        count = 0
        max_count = 0
        for val in data:
            if val == value:
                count += 1
                max_count = max(max_count, count)
            else:
                count = 0
        return max_count
    
    def _max_consecutive_low(self, data, threshold=10):
        """ArdÄ±ÅŸÄ±k dÃ¼ÅŸÃ¼k tÃ¼ketim periyodu"""
        count = 0
        max_count = 0
        for val in data:
            if val < threshold:
                count += 1
                max_count = max(max_count, count)
            else:
                count = 0
        return max_count
    
    def _calculate_trend(self, data):
        """Genel trend"""
        if len(data) < 2:
            return 0
        x = np.arange(len(data))
        return np.polyfit(x, data, 1)[0]
    
    def _count_negative_trends(self, data, window=6):
        """Negatif trend dÃ¶nem sayÄ±sÄ±"""
        if len(data) < window:
            return 0
        count = 0
        for i in range(len(data) - window + 1):
            window_data = data[i:i+window]
            if self._calculate_trend(window_data) < -1:
                count += 1
        return count
    
    def _calculate_seasonal_variation(self, data):
        """Mevsimsel varyasyon (kÄ±ÅŸ-yaz farkÄ±)"""
        if len(data) < 12:
            return 0
        # 12 aylÄ±k periyotlara bÃ¶l
        years = len(data) // 12
        if years == 0:
            return 0
        
        variations = []
        for year in range(years):
            year_data = data[year*12:(year+1)*12]
            if len(year_data) == 12:
                winter = np.mean([year_data[11], year_data[0], year_data[1]])  # AralÄ±k, Ocak, Åubat
                summer = np.mean([year_data[5], year_data[6], year_data[7]])   # Haziran, Temmuz, AÄŸustos
                if summer > 0:
                    variations.append((winter - summer) / summer)
        
        return np.mean(variations) if len(variations) > 0 else 0
    
    def _check_missing_winter_peak(self, data):
        """KÄ±ÅŸ zirvesi eksikliÄŸi kontrolÃ¼"""
        if len(data) < 12:
            return 0
        years = len(data) // 12
        missing_count = 0
        
        for year in range(years):
            year_data = data[year*12:(year+1)*12]
            if len(year_data) == 12:
                winter_avg = np.mean([year_data[11], year_data[0], year_data[1]])
                summer_avg = np.mean([year_data[5], year_data[6], year_data[7]])
                # Normal evlerde kÄ±ÅŸ en az 1.5 kat fazla olmalÄ±
                if winter_avg < summer_avg * 1.2:
                    missing_count += 1
        
        return missing_count
    
    def calculate_risk_score(self, features_df):
        """
        KaÃ§ak kullanÄ±m risk skoru hesapla
        
        AÄIRLIKLAR (verimizdeki patternlere gÃ¶re):
        - SÄ±fÄ±r tÃ¼ketim oranÄ±: x100 (en Ã¶nemli!)
        - ArdÄ±ÅŸÄ±k sÄ±fÄ±r aylar: x20
        - Ani dÃ¼ÅŸÃ¼ÅŸ: x15
        - DÃ¼ÅŸÃ¼k tÃ¼ketim oranÄ±: x50
        """
        risk = np.zeros(len(features_df))
        
        # 1. SÄ±fÄ±r tÃ¼ketim (Ã‡OK Ã–NEMLÄ°!)
        risk += features_df['zero_ratio'] * 100
        risk += features_df['consecutive_zero_months'] * 20
        
        # 2. DÃ¼ÅŸÃ¼k tÃ¼ketim
        risk += features_df['low_consumption_ratio'] * 50
        risk += features_df['consecutive_low_months'] * 10
        
        # 3. Ani dÃ¼ÅŸÃ¼ÅŸler
        risk += features_df['sudden_drops'] * 15
        risk += features_df['max_drop_percentage'] / 10
        
        # 4. Negatif trendler
        risk += features_df['negative_trend_periods'] * 12
        
        # 5. Mevsimsel anormallik
        risk += features_df['missing_winter_peak'] * 8
        
        # 6. YÃ¼ksek deÄŸiÅŸkenlik
        risk += features_df['coefficient_of_variation'] * 5
        
        return risk
    
    def detect_anomalies(self, features_df):
        """Anomali tespiti"""
        facility_ids = features_df['facility_id'].values
        feature_columns = features_df.drop('facility_id', axis=1)
        
        # Normalizasyon
        features_scaled = self.scaler.fit_transform(feature_columns)
        
        # ML modeli ile anomali tespiti
        predictions = self.model.fit_predict(features_scaled)
        anomaly_scores = self.model.score_samples(features_scaled)
        
        # SonuÃ§lar
        results = features_df.copy()
        results['is_anomaly'] = predictions == -1
        results['ml_anomaly_score'] = -anomaly_scores
        results['risk_score'] = self.calculate_risk_score(features_df)
        
        # Risk seviyesi
        results['risk_level'] = pd.cut(results['risk_score'], 
                                       bins=[-np.inf, 20, 50, 100, np.inf],
                                       labels=['DÃ¼ÅŸÃ¼k', 'Orta', 'YÃ¼ksek', 'Ã‡ok YÃ¼ksek'])
        
        return results.sort_values('risk_score', ascending=False)


def create_excel_download(df):
    """Excel indirme butonu oluÅŸtur"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Anomali Tespiti')
    output.seek(0)
    return output


def main():
    st.title("âš ï¸ DoÄŸalgaz KaÃ§ak KullanÄ±m Anomali Tespit Sistemi")
    
    st.markdown("""
    ### ğŸ“Š Sistem NasÄ±l Ã‡alÄ±ÅŸÄ±r?
    
    **Verinizdeki ÅŸÃ¼pheli patternleri tespit eder:**
    
    1. **SÄ±fÄ±r/DÃ¼ÅŸÃ¼k TÃ¼ketim**: Uzun sÃ¼re sÄ±fÄ±r veya Ã§ok dÃ¼ÅŸÃ¼k tÃ¼ketim (sayaÃ§ manipÃ¼lasyonu)
    2. **Ani DÃ¼ÅŸÃ¼ÅŸler**: Normal tÃ¼ketimden aniden %50+ dÃ¼ÅŸÃ¼ÅŸ
    3. **Uzun SÃ¼reli DÃ¼ÅŸÃ¼k DÃ¶nemler**: 6+ ay boyunca dÃ¼ÅŸÃ¼k tÃ¼ketim
    4. **Mevsimsel Anormallik**: KÄ±ÅŸ-yaz farkÄ± olmamasÄ± (normal evlerde kÄ±ÅŸ 2-3x fazla)
    5. **DÃ¼zensizlik**: TutarsÄ±z, aÅŸÄ±rÄ± deÄŸiÅŸken tÃ¼ketim paterni
    
    ---
    """)
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Ayarlar")
        contamination = st.slider(
            "Beklenen Anomali OranÄ± (%)",
            min_value=5,
            max_value=30,
            value=15,
            help="Verinizdeki kaÃ§ak kullanÄ±m oranÄ± tahmini. Daha yÃ¼ksek deÄŸer = daha fazla tespit"
        ) / 100
        
        st.markdown("---")
        st.markdown("""
        ### ğŸ“ Dosya FormatÄ±
        - Excel (.xlsx, .xls)
        - CSV (virgÃ¼l/boÅŸluk ayrÄ±lmÄ±ÅŸ)
        
        **SÃ¼tun YapÄ±sÄ±:**
        - 1. SÃ¼tun: Tesisat ID
        - DiÄŸer SÃ¼tunlar: AylÄ±k tÃ¼ketim deÄŸerleri
        """)
    
    # Dosya yÃ¼kleme
    uploaded_file = st.file_uploader(
        "ğŸ“‚ Excel/CSV DosyanÄ±zÄ± YÃ¼kleyin",
        type=['xlsx', 'xls', 'csv', 'txt'],
        help="Tesisat ID'leri ve aylÄ±k tÃ¼ketim deÄŸerlerini iÃ§eren dosya"
    )
    
    if uploaded_file is not None:
        try:
            # DedektÃ¶r oluÅŸtur
            detector = GasFraudDetector(contamination=contamination)
            
            # Veriyi yÃ¼kle
            with st.spinner("ğŸ“¥ Veri yÃ¼kleniyor..."):
                df = detector.load_excel(uploaded_file)
                
            if df is not None:
                st.success(f"âœ… {len(df)} tesisat yÃ¼klendi!")
                
                # Veri Ã¶nizleme
                with st.expander("ğŸ‘ï¸ Veri Ã–nizleme (Ä°lk 10 SatÄ±r)"):
                    st.dataframe(df.head(10))
                
                # Analiz butonu
                if st.button("ğŸ” ANOMALÄ° TESPÄ°TÄ° BAÅLAT", type="primary"):
                    
                    # Ã–zellik Ã§Ä±karma
                    with st.spinner("ğŸ”§ Ã–zellikler Ã§Ä±karÄ±lÄ±yor..."):
                        features = detector.extract_features()
                    
                    st.success(f"âœ… {len(features)} tesisat iÃ§in Ã¶zellikler Ã§Ä±karÄ±ldÄ±")
                    
                    # Anomali tespiti
                    with st.spinner("ğŸ¤– Makine Ã¶ÄŸrenmesi modeli Ã§alÄ±ÅŸÄ±yor..."):
                        results = detector.detect_anomalies(features)
                    
                    # SONUÃ‡LAR
                    st.markdown("---")
                    st.header("ğŸ“Š ANALÄ°Z SONUÃ‡LARI")
                    
                    # Ã–zet metrikler
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Toplam Tesisat", len(results))
                    with col2:
                        anomaly_count = results['is_anomaly'].sum()
                        st.metric("Tespit Edilen Anomali", anomaly_count)
                    with col3:
                        anomaly_rate = (anomaly_count / len(results) * 100)
                        st.metric("Anomali OranÄ±", f"{anomaly_rate:.1f}%")
                    with col4:
                        high_risk = (results['risk_level'].isin(['YÃ¼ksek', 'Ã‡ok YÃ¼ksek'])).sum()
                        st.metric("YÃ¼ksek Risk", high_risk)
                    
                    # Risk daÄŸÄ±lÄ±mÄ±
                    st.subheader("ğŸ“ˆ Risk Seviyesi DaÄŸÄ±lÄ±mÄ±")
                    risk_dist = results['risk_level'].value_counts()
                    fig = px.pie(values=risk_dist.values, names=risk_dist.index, 
                                color_discrete_sequence=['green', 'yellow', 'orange', 'red'])
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # En ÅŸÃ¼pheli tesisatlar
                    st.subheader("ğŸš¨ EN ÅÃœPHELÄ° TESÄ°SATLAR")
                    
                    top_n = st.slider("GÃ¶sterilecek tesisat sayÄ±sÄ±", 10, 50, 20)
                    top_suspicious = results.head(top_n)
                    
                    # Ã–nemli sÃ¼tunlarÄ± seÃ§
                    display_cols = [
                        'facility_id', 'risk_score', 'risk_level', 'is_anomaly',
                        'zero_ratio', 'zero_count', 'consecutive_zero_months',
                        'low_consumption_ratio', 'sudden_drops', 'max_drop_percentage',
                        'consecutive_low_months', 'mean_consumption'
                    ]
                    
                    # YÃ¼zdeleri dÃ¼zenle
                    display_df = top_suspicious[display_cols].copy()
                    display_df['zero_ratio'] = (display_df['zero_ratio'] * 100).round(1)
                    display_df['low_consumption_ratio'] = (display_df['low_consumption_ratio'] * 100).round(1)
                    display_df['max_drop_percentage'] = display_df['max_drop_percentage'].round(1)
                    display_df['mean_consumption'] = display_df['mean_consumption'].round(2)
                    display_df['risk_score'] = display_df['risk_score'].round(2)
                    
                    # SÃ¼tun isimlerini TÃ¼rkÃ§eleÅŸtir
                    display_df.columns = [
                        'Tesisat ID', 'Risk Skoru', 'Risk Seviyesi', 'Anomali',
                        'SÄ±fÄ±r TÃ¼k. %', 'SÄ±fÄ±r Ay', 'ArdÄ±ÅŸÄ±k SÄ±fÄ±r',
                        'DÃ¼ÅŸÃ¼k TÃ¼k. %', 'Ani DÃ¼ÅŸÃ¼ÅŸ', 'Maks DÃ¼ÅŸÃ¼ÅŸ %',
                        'ArdÄ±ÅŸÄ±k DÃ¼ÅŸÃ¼k Ay', 'Ort. TÃ¼ketim'
                    ]
                    
                    # Renkli tablo
                    st.dataframe(
                        display_df.style.background_gradient(subset=['Risk Skoru'], cmap='Reds'),
                        use_container_width=True,
                        height=600
                    )
                    
                    # Risk skoru daÄŸÄ±lÄ±mÄ±
                    st.subheader("ğŸ“Š Risk Skoru DaÄŸÄ±lÄ±mÄ±")
                    fig2 = px.histogram(results, x='risk_score', nbins=50,
                                       labels={'risk_score': 'Risk Skoru', 'count': 'Tesisat SayÄ±sÄ±'})
                    st.plotly_chart(fig2, use_container_width=True)
                    
                    # Excel indirme butonlarÄ±
                    st.markdown("---")
                    st.subheader("ğŸ’¾ SonuÃ§larÄ± Ä°ndir")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # TÃ¼m sonuÃ§lar
                        excel_all = create_excel_download(results)
                        st.download_button(
                            label="ğŸ“¥ TÃ¼m SonuÃ§larÄ± Ä°ndir (Excel)",
                            data=excel_all,
                            file_name="tum_anomali_sonuclari.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    
                    with col2:
                        # Sadece ÅŸÃ¼pheliler
                        suspicious_only = results[results['risk_level'].isin(['YÃ¼ksek', 'Ã‡ok YÃ¼ksek'])]
                        excel_suspicious = create_excel_download(suspicious_only)
                        st.download_button(
                            label="ğŸ“¥ Sadece ÅÃ¼pheli Tesisatlar (Excel)",
                            data=excel_suspicious,
                            file_name="supheli_tesisatlar.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    
                    # DetaylÄ± aÃ§Ä±klama
                    with st.expander("â„¹ï¸ Risk Skoru NasÄ±l HesaplanÄ±yor?"):
                        st.markdown("""
                        **Risk Skoru FormÃ¼lÃ¼:**
                        
                        - **SÄ±fÄ±r TÃ¼ketim OranÄ±** Ã— 100 (en Ã¶nemli faktÃ¶r)
                        - **ArdÄ±ÅŸÄ±k SÄ±fÄ±r Aylar** Ã— 20
                        - **DÃ¼ÅŸÃ¼k TÃ¼ketim OranÄ±** Ã— 50
                        - **ArdÄ±ÅŸÄ±k DÃ¼ÅŸÃ¼k Aylar** Ã— 10
                        - **Ani DÃ¼ÅŸÃ¼ÅŸ SayÄ±sÄ±** Ã— 15
                        - **Maksimum DÃ¼ÅŸÃ¼ÅŸ YÃ¼zdesi** Ã· 10
                        - **Negatif Trend DÃ¶nemleri** Ã— 12
                        - **Mevsimsel Anormallik** Ã— 8
                        - **DeÄŸiÅŸkenlik KatsayÄ±sÄ±** Ã— 5
                        
                        **Risk Seviyeleri:**
                        - ğŸŸ¢ DÃ¼ÅŸÃ¼k: 0-20
                        - ğŸŸ¡ Orta: 20-50
                        - ğŸŸ  YÃ¼ksek: 50-100
                        - ğŸ”´ Ã‡ok YÃ¼ksek: 100+
                        """)
                        
        except Exception as e:
            st.error(f"âŒ Hata oluÅŸtu: {str(e)}")
            st.info("LÃ¼tfen dosya formatÄ±nÄ± kontrol edin. Ä°lk sÃ¼tun Tesisat ID, diÄŸer sÃ¼tunlar aylÄ±k tÃ¼ketim deÄŸerleri olmalÄ±.")


if __name__ == "__main__":
    main()
