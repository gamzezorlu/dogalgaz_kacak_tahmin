import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import warnings
from io import BytesIO

warnings.filterwarnings('ignore')

# -------------------- Sayfa konfigÃ¼rasyonu --------------------
st.set_page_config(
    page_title="DoÄŸalgaz TÃ¼ketim Anomali Tespit",
    page_icon="ðŸ”¥",
    layout="wide"
)

st.title("ðŸ”¥ DoÄŸalgaz TÃ¼ketim Anomali Tespit Sistemi")
st.markdown("---")

# -------------------- Yan panel - Dosya yÃ¼kleme --------------------
st.sidebar.header("ðŸ“ Dosya YÃ¼kleme")
uploaded_file = st.sidebar.file_uploader(
    "CSV veya Excel dosyasÄ± seÃ§in",
    type=['csv', 'xlsx', 'xls'],
    help="Tesisat numarasÄ±, bina numarasÄ± ve aylÄ±k tÃ¼ketim verilerini iÃ§eren dosya"
)

# -------------------- Parametreler --------------------
st.sidebar.header("âš™ï¸ Analiz Parametreleri")
kis_tuketim_esigi = st.sidebar.slider(
    "KÄ±ÅŸ ayÄ± dÃ¼ÅŸÃ¼k tÃ¼ketim eÅŸiÄŸi (mÂ³/ay)",
    min_value=10, max_value=100, value=30,
    help="KÄ±ÅŸ aylarÄ±nda bu deÄŸerin altÄ±ndaki tÃ¼ketim ÅŸÃ¼pheli kabul edilir"
)

bina_ort_dusuk_oran = st.sidebar.slider(
    "Bina ortalamasÄ±ndan dÃ¼ÅŸÃ¼k olma oranÄ± (%)",
    min_value=30, max_value=90, value=60,
    help="Bina ortalamasÄ±ndan bu oranda dÃ¼ÅŸÃ¼k tÃ¼ketim ÅŸÃ¼pheli kabul edilir"
)

ani_dusus_orani = st.sidebar.slider(
    "Ani dÃ¼ÅŸÃ¼ÅŸ oranÄ± (%)",
    min_value=40, max_value=90, value=70,
    help="Ã–nceki kÄ±ÅŸ aylarÄ±na gÃ¶re bu oranda dÃ¼ÅŸÃ¼ÅŸ ÅŸÃ¼pheli kabul edilir"
)

min_onceki_kis_tuketim = st.sidebar.slider(
    "Minimum Ã¶nceki kÄ±ÅŸ tÃ¼ketimi (mÂ³)",
    min_value=50, max_value=200, value=100,
    help="Ani dÃ¼ÅŸÃ¼ÅŸ tespiti iÃ§in Ã¶nceki kÄ±ÅŸ aylarÄ±nda minimum tÃ¼ketim"
)

# -------------------- YardÄ±mcÄ±lar --------------------
def load_data(file):
    """DosyayÄ± yÃ¼kle ve temizle"""
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file, encoding='utf-8')
        else:
            df = pd.read_excel(file)
        df.columns = df.columns.str.strip()
        return df
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(file, encoding='latin1')
            df.columns = df.columns.str.strip()
            return df
        except Exception as e:
            st.error(f"Dosya yÃ¼kleme hatasÄ±: {str(e)}")
            return None
    except Exception as e:
        st.error(f"Dosya yÃ¼kleme hatasÄ±: {str(e)}")
        return None

def detect_data_format(df):
    """Veri formatÄ±nÄ± tespit et"""
    columns = [col.lower().strip() for col in df.columns]
    raw_indicators = ['belge tarihi', 'tÃ¼ketim noktasÄ±', 'baÄŸlantÄ± nesnesi', 'sm3']
    pivot_indicators = ['tesisat', 'bina']
    raw_score = sum(1 for indicator in raw_indicators if any(indicator in col for col in columns))
    pivot_score = sum(1 for indicator in pivot_indicators if any(indicator in col for col in columns))
    date_format_score = sum(
        1 for col in df.columns
        if isinstance(col, str) and '/' in col and len(col.split('/')) == 2
    )
    if raw_score >= 3:
        return 'raw'
    elif pivot_score >= 1 or date_format_score >= 3:
        return 'pivot'
    else:
        return 'unknown'

def _safe_sort_date_cols(cols):
    def keyf(x):
        try:
            y, m = x.split('/')
            return (int(y), int(m))
        except Exception:
            return (9999, 99)
    return sorted(cols, key=keyf)

def convert_raw_to_pivot(df):
    """Raw veriyi pivot formata dÃ¶nÃ¼ÅŸtÃ¼r - Completely Fixed version"""
    try:
        st.info("ðŸ” Veri dÃ¶nÃ¼ÅŸtÃ¼rme baÅŸlÄ±yor...")
        
        # Kolon isimlerini normalize et
        column_mapping = {}
        for col in df.columns:
            col_lower = str(col).lower().strip()
            if 'belge tarihi' in col_lower or col_lower == 'tarih':
                column_mapping[col] = 'belge_tarihi'
            elif 'tÃ¼ketim noktasÄ±' in col_lower or 'tesisat' in col_lower:
                column_mapping[col] = 'tesisat_no'
            elif 'baÄŸlantÄ± nesnesi' in col_lower or 'bina' in col_lower:
                column_mapping[col] = 'bina_no'
            elif 'sm3' in col_lower or 'tÃ¼ketim' in col_lower:
                column_mapping[col] = 'tuketim'

        df_renamed = df.rename(columns=column_mapping)
        st.write(f"âœ“ Kolon eÅŸleÅŸtirmesi: {column_mapping}")

        # Gerekli kolon kontrolÃ¼
        required = ['belge_tarihi', 'tesisat_no', 'bina_no', 'tuketim']
        missing = [c for c in required if c not in df_renamed.columns]
        if missing:
            st.error(f"âŒ Eksik kolonlar: {missing}")
            st.info(f"Mevcut kolonlar: {list(df_renamed.columns)}")
            return None

        # Veri temizleme ve tip dÃ¶nÃ¼ÅŸÃ¼mleri
        st.info("ðŸ§¹ Veri temizleniyor...")
        df_clean = df_renamed.copy()
        
        # Ã–nce boyutu kaydet
        original_size = len(df_clean)
        
        # Tarih sÃ¼tununu temizle
        df_clean['belge_tarihi'] = pd.to_datetime(
            df_clean['belge_tarihi'], errors='coerce', dayfirst=True
        )
        
        # TÃ¼ketim deÄŸerlerini sayÄ±sal yap
        df_clean['tuketim'] = pd.to_numeric(
            df_clean['tuketim'], errors='coerce'
        )
        
        # String sÃ¼tunlarÄ± temizle
        df_clean['tesisat_no'] = df_clean['tesisat_no'].astype(str).str.strip()
        df_clean['bina_no'] = df_clean['bina_no'].astype(str).str.strip()
        
        # GeÃ§ersiz kayÄ±tlarÄ± temizle
        df_clean = df_clean.dropna(subset=['belge_tarihi'])
        after_date_clean = len(df_clean)
        
        # NaN tÃ¼ketimleri 0 yap
        df_clean['tuketim'] = df_clean['tuketim'].fillna(0)
        
        # YÄ±l/ay sÃ¼tunu oluÅŸtur
        df_clean['yil_ay'] = df_clean['belge_tarihi'].dt.strftime('%Y/%m')
        
        # 'nan' string deÄŸerlerini temizle
        df_clean = df_clean[
            (df_clean['tesisat_no'] != 'nan') & 
            (df_clean['bina_no'] != 'nan') & 
            (df_clean['yil_ay'].notna()) &
            (df_clean['tesisat_no'] != '') & 
            (df_clean['bina_no'] != '')
        ]
        
        final_clean_size = len(df_clean)
        
        st.write(f"ðŸ“Š Veri temizleme raporu:")
        st.write(f"   â€¢ BaÅŸlangÄ±Ã§: {original_size:,} kayÄ±t")
        st.write(f"   â€¢ Tarih temizleme sonrasÄ±: {after_date_clean:,} kayÄ±t")
        st.write(f"   â€¢ Son temizlik sonrasÄ±: {final_clean_size:,} kayÄ±t")
        
        if df_clean.empty:
            st.error("âŒ Temizleme sonrasÄ± veri kalmadÄ±!")
            return None
        
        # Duplicate kontrolÃ¼ ve birleÅŸtirme
        st.info("ðŸ”„ Veriler gruplandÄ±rÄ±lÄ±yor...")
        
        # Ã–nce duplicate kontrolÃ¼ yapalÄ±m
        duplicates = df_clean.groupby(['tesisat_no', 'bina_no', 'yil_ay']).size()
        duplicate_count = (duplicates > 1).sum()
        if duplicate_count > 0:
            st.write(f"âš ï¸ {duplicate_count} adet duplicate grup bulundu, toplamlarÄ± alÄ±nacak")
        
        # Gruplama ve toplama iÅŸlemi
        grouped_df = df_clean.groupby(
            ['tesisat_no', 'bina_no', 'yil_ay'], as_index=False
        )['tuketim'].sum()
        
        st.write(f"âœ“ GruplandÄ±rma tamamlandÄ±: {len(grouped_df):,} benzersiz kayÄ±t")
        
        # Manuel pivot iÅŸlemi - Dictionary tabanlÄ±
        st.info("ðŸ“Š Pivot table oluÅŸturuluyor...")
        
        # TÃ¼m benzersiz deÄŸerleri al
        unique_tesisats = sorted(grouped_df['tesisat_no'].unique())
        unique_binas = sorted(grouped_df['bina_no'].unique())  
        unique_dates = sorted(grouped_df['yil_ay'].unique())
        
        st.write(f"ðŸ“ˆ Pivot boyutlarÄ±:")
        st.write(f"   â€¢ Tesisat sayÄ±sÄ±: {len(unique_tesisats)}")
        st.write(f"   â€¢ Bina sayÄ±sÄ±: {len(unique_binas)}")
        st.write(f"   â€¢ Tarih sayÄ±sÄ±: {len(unique_dates)}")
        
        # Pivot dictionary'si oluÅŸtur
        pivot_dict = {}
        
        # Her grup iÃ§in pivot dictionary'yi doldur
        for _, row in grouped_df.iterrows():
            key = (row['tesisat_no'], row['bina_no'])
            date = row['yil_ay']
            value = row['tuketim']
            
            if key not in pivot_dict:
                pivot_dict[key] = {'tesisat_no': row['tesisat_no'], 'bina_no': row['bina_no']}
                # TÃ¼m tarihleri 0 ile baÅŸlat
                for d in unique_dates:
                    pivot_dict[key][d] = 0
            
            # DeÄŸeri gÃ¼ncelle
            pivot_dict[key][date] = value
        
        # Dictionary'yi DataFrame'e Ã§evir
        pivot_rows = list(pivot_dict.values())
        final_df = pd.DataFrame(pivot_rows)
        
        # SÃ¼tun sÄ±rasÄ±nÄ± dÃ¼zenle
        date_cols = [col for col in final_df.columns if col not in ['tesisat_no', 'bina_no']]
        date_cols = _safe_sort_date_cols(date_cols)
        final_df = final_df[['tesisat_no', 'bina_no'] + date_cols]
        
        st.write(f"âœ… Pivot table oluÅŸturuldu: {len(final_df)} satÄ±r x {len(final_df.columns)} sÃ¼tun")
        
        return final_df

    except Exception as e:
        st.error(f"âŒ Veri dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {str(e)}")
        st.info("ðŸ” Hata detaylarÄ±:")
        
        # Hata durumunda debug bilgileri gÃ¶ster
        try:
            if 'df_clean' in locals():
                st.write(f"df_clean shape: {df_clean.shape}")
                st.write(f"df_clean columns: {list(df_clean.columns)}")
                st.write("Ä°lk 3 satÄ±r:")
                st.dataframe(df_clean.head(3))
            if 'grouped_df' in locals():
                st.write(f"grouped_df shape: {grouped_df.shape}")
                st.write("grouped_df sample:")
                st.dataframe(grouped_df.head(3))
        except:
            st.write("Debug bilgileri alÄ±namadÄ±")
            
        import traceback
        st.code(traceback.format_exc())
        return None

def parse_date_columns(df):
    """Tarih sÃ¼tunlarÄ±nÄ± (YYYY/MM) tespit et ve sÄ±rala"""
    date_columns = []
    other_columns = []
    for col in df.columns:
        if isinstance(col, str) and '/' in col:
            parts = col.split('/')
            if len(parts) == 2 and len(parts[0]) == 4:
                try:
                    int(parts[0]); int(parts[1])
                    date_columns.append(col)
                    continue
                except Exception:
                    pass
        other_columns.append(col)
    date_columns = _safe_sort_date_cols(date_columns)
    return date_columns, other_columns

def get_season(month):
    """AyÄ± mevsime gÃ¶re kategorize et"""
    if month in [12, 1, 2]:
        return "KÄ±ÅŸ"
    elif month in [3, 4, 5]:
        return "Ä°lkbahar"
    elif month in [6, 7, 8]:
        return "Yaz"
    else:
        return "Sonbahar"

def analyze_consumption_patterns(df, date_columns, tesisat_col, bina_col):
    """TÃ¼ketim paternlerini analiz et"""
    results = []

    for _, row in df.iterrows():
        tesisat_no = row[tesisat_col]
        bina_no = row[bina_col]

        # AylÄ±k tÃ¼ketim verilerini al
        consumption_data = []
        for date_col in date_columns:
            try:
                value = row[date_col]
                if pd.notna(value) and value != '':
                    year, month = date_col.split('/')
                    consumption_data.append({
                        'year': int(year),
                        'month': int(month),
                        'consumption': float(value) if value != 0 else 0,
                        'season': get_season(int(month)),
                        'date_str': date_col
                    })
            except Exception:
                continue

        if not consumption_data:
            continue

        cons_df = pd.DataFrame(consumption_data).sort_values(['year', 'month'])

        # Mevsimsel ortalamalar (sÄ±fÄ±r olmayan)
        nonzero = cons_df[cons_df['consumption'] > 0]
        seasonal_avg = nonzero.groupby('season')['consumption'].mean() if not nonzero.empty else pd.Series(dtype=float)

        kis_tuketim = float(seasonal_avg.get('KÄ±ÅŸ', 0) or 0)
        yaz_tuketim = float(seasonal_avg.get('Yaz', 0) or 0)

        anomalies = []

        # 1) KÄ±ÅŸ dÃ¼ÅŸÃ¼k tÃ¼ketim
        if 0 < kis_tuketim < kis_tuketim_esigi:
            anomalies.append(f"KÄ±ÅŸ ayÄ± dÃ¼ÅŸÃ¼k tÃ¼ketim: {kis_tuketim:.1f} mÂ³/ay")

        # 2) KÄ±ÅŸ-yaz farkÄ± az
        if kis_tuketim > 0 and yaz_tuketim > 0:
            if abs(kis_tuketim - yaz_tuketim) < 10:
                anomalies.append(f"KÄ±ÅŸ-yaz tÃ¼ketim farkÄ± az: KÄ±ÅŸ {kis_tuketim:.1f}, Yaz {yaz_tuketim:.1f}")

        # 3) Toplam Ã§ok dÃ¼ÅŸÃ¼k
        total_consumption = cons_df['consumption'].sum()
        if total_consumption < 100:
            anomalies.append(f"Toplam tÃ¼ketim Ã§ok dÃ¼ÅŸÃ¼k: {total_consumption:.1f} mÂ³")

        # 4) Ã‡ok fazla sÄ±fÄ±r
        zero_months = int((cons_df['consumption'] == 0).sum())
        if zero_months > 6:
            anomalies.append(f"Ã‡ok fazla sÄ±fÄ±r tÃ¼ketim: {zero_months} ay")

        # 5) KÄ±ÅŸ aylarÄ±nda ani dÃ¼ÅŸÃ¼ÅŸ
        kis_aylari = cons_df[cons_df['season'] == 'KÄ±ÅŸ'].copy()
        if len(kis_aylari) >= 4:
            kis_yillik = kis_aylari.groupby('year')['consumption'].mean()
            yillik_ort = kis_yillik[kis_yillik > 0]
            if len(yillik_ort) >= 2:
                yillar = sorted(yillik_ort.index)
                for i in range(1, len(yillar)):
                    oy, my = yillar[i-1], yillar[i]
                    onceki, mevcut = yillik_ort[oy], yillik_ort[my]
                    if (onceki >= min_onceki_kis_tuketim and
                        mevcut < onceki * (1 - ani_dusus_orani/100)):
                        dus = ((onceki - mevcut) / onceki) * 100
                        anomalies.append(
                            f"Ani kÄ±ÅŸ dÃ¼ÅŸÃ¼ÅŸÃ¼: {oy} ({onceki:.1f}) â†’ {my} ({mevcut:.1f}), %{dus:.1f} dÃ¼ÅŸÃ¼ÅŸ"
                        )

                if len(yillar) >= 2:
                    oy, my = yillar[-2], yillar[-1]
                    onceki, mevcut = yillik_ort[oy], yillik_ort[my]
                    if (onceki >= min_onceki_kis_tuketim and
                        mevcut < onceki * (1 - ani_dusus_orani/100)):
                        dus = ((onceki - mevcut) / onceki) * 100
                        anomalies.append(f"Son yÄ±l ani dÃ¼ÅŸÃ¼ÅŸ: {oy} â†’ {my}, %{dus:.1f} dÃ¼ÅŸÃ¼ÅŸ")

        # 6) Bina ortalamasÄ± karÅŸÄ±laÅŸtÄ±rma
        bina_tesisatlari = df[df[bina_col] == bina_no]
        if len(bina_tesisatlari) > 1:
            bina_tuketimleri = []
            for _, br in bina_tesisatlari.iterrows():
                vals = []
                for dc in date_columns:
                    v = br.get(dc, np.nan)
                    if pd.notna(v) and float(v) > 0:
                        vals.append(float(v))
                if vals:
                    bina_tuketimleri.append(np.mean(vals))

            if len(bina_tuketimleri) > 1:
                bina_ort = float(np.mean(bina_tuketimleri))
                mevcut_ort = float(nonzero['consumption'].mean()) if not nonzero.empty else 0
                if mevcut_ort > 0 and mevcut_ort < bina_ort * (1 - bina_ort_dusuk_oran/100):
                    anomalies.append(f"Bina ortalamasÄ±ndan %{bina_ort_dusuk_oran} dÃ¼ÅŸÃ¼k: {mevcut_ort:.1f} vs {bina_ort:.1f}")

        # KÄ±ÅŸ trend etiketi
        kis_trend = "Stabil"
        if len(kis_aylari) >= 4:
            kis_yillik = kis_aylari.groupby('year')['consumption'].mean()
            yillik_ort = kis_yillik[kis_yillik > 0]
            if len(yillik_ort) >= 2:
                yillar = sorted(yillik_ort.index)
                ilk_yil = yillik_ort[yillar[0]]
                son_yil = yillik_ort[yillar[-1]]
                if son_yil < ilk_yil * 0.5:
                    kis_trend = "Åžiddetli DÃ¼ÅŸÃ¼ÅŸ"
                elif son_yil < ilk_yil * 0.7:
                    kis_trend = "Orta DÃ¼ÅŸÃ¼ÅŸ"
                elif son_yil > ilk_yil * 1.5:
                    kis_trend = "ArtÄ±ÅŸ"

        results.append({
            'tesisat_no': tesisat_no,
            'bina_no': bina_no,
            'kis_tuketim': kis_tuketim,
            'yaz_tuketim': yaz_tuketim,
            'toplam_tuketim': total_consumption,
            'ortalama_tuketim': float(nonzero['consumption'].mean()) if not nonzero.empty else 0,
            'kis_trend': kis_trend,
            'anomali_sayisi': len(anomalies),
            'anomaliler': '; '.join(anomalies) if anomalies else 'Normal',
            'suspicion_level': 'ÅžÃ¼pheli' if anomalies else 'Normal'
        })

    return pd.DataFrame(results)

def create_visualizations(results_df, original_df, date_columns):
    """GÃ¶rselleÅŸtirmeler oluÅŸtur"""

    # 1) Anomali daÄŸÄ±lÄ±mÄ±
    fig1 = px.histogram(
        results_df,
        x='anomali_sayisi',
        title="Anomali SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±",
        color_discrete_sequence=['#FF6B6B']
    )
    st.plotly_chart(fig1, use_container_width=True)

    # 2) ÅžÃ¼pheli vs Normal
    suspicion_counts = results_df['suspicion_level'].value_counts()
    fig2 = px.pie(
        values=suspicion_counts.values,
        names=suspicion_counts.index,
        title="ÅžÃ¼pheli vs Normal Tesisatlar",
        color_discrete_map={'ÅžÃ¼pheli': '#FF6B6B', 'Normal': '#4ECDC4'}
    )
    st.plotly_chart(fig2, use_container_width=True)

    # 3) KÄ±ÅŸ Trend Analizi
    trend_counts = results_df['kis_trend'].value_counts()
    fig3 = px.bar(
        x=trend_counts.index,
        y=trend_counts.values,
        title="KÄ±ÅŸ AyÄ± TÃ¼ketim Trend Analizi",
        color=trend_counts.values,
        color_continuous_scale='Reds'
    )
    fig3.update_layout(showlegend=False)
    st.plotly_chart(fig3, use_container_width=True)

    # 4) KÄ±ÅŸ vs Yaz
    fig4 = px.scatter(
        results_df,
        x='yaz_tuketim',
        y='kis_tuketim',
        color='suspicion_level',
        size='anomali_sayisi',
        title="KÄ±ÅŸ vs Yaz TÃ¼ketim KarÅŸÄ±laÅŸtÄ±rmasÄ±",
        labels={'yaz_tuketim': 'Yaz TÃ¼ketimi (mÂ³)', 'kis_tuketim': 'KÄ±ÅŸ TÃ¼ketimi (mÂ³)'},
        color_discrete_map={'ÅžÃ¼pheli': '#FF6B6B', 'Normal': '#4ECDC4'},
        hover_data=['kis_trend']
    )

    max_val = max(float(results_df['yaz_tuketim'].max() or 0),
                  float(results_df['kis_tuketim'].max() or 0))
    if max_val > 0:
        fig4.add_trace(go.Scatter(
            x=[0, max_val],
            y=[0, max_val],
            mode='lines',
            name='EÅŸit TÃ¼ketim Ã‡izgisi',
            line=dict(dash='dash', color='gray')
        ))
    st.plotly_chart(fig4, use_container_width=True)

    # 5) Trend x Durum
    trend_anomali = results_df.groupby(['kis_trend', 'suspicion_level']).size().reset_index(name='count')
    fig5 = px.bar(
        trend_anomali,
        x='kis_trend',
        y='count',
        color='suspicion_level',
        title="Trend BazÄ±nda Anomali DaÄŸÄ±lÄ±mÄ±",
        color_discrete_map={'ÅžÃ¼pheli': '#FF6B6B', 'Normal': '#4ECDC4'}
    )
    st.plotly_chart(fig5, use_container_width=True)

# -------------------- Ana uygulama --------------------
if uploaded_file is not None:
    df = load_data(uploaded_file)

    if df is not None:
        st.success("âœ… Dosya baÅŸarÄ±yla yÃ¼klendi!")

        data_format = detect_data_format(df)

        if data_format == 'raw':
            st.info("ðŸ”„ Raw veri formatÄ± tespit edildi. Pivot formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
            df_pivot = convert_raw_to_pivot(df)

            if df_pivot is not None:
                st.success("âœ… Veri baÅŸarÄ±yla pivot formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼!")
                c1, c2 = st.columns(2)
                with c1: st.metric("Orijinal SatÄ±r SayÄ±sÄ±", len(df))
                with c2: st.metric("Pivot SonrasÄ± Tesisat SayÄ±sÄ±", len(df_pivot))
                df = df_pivot
            else:
                st.error("âŒ Veri dÃ¶nÃ¼ÅŸtÃ¼rme baÅŸarÄ±sÄ±z!")
                st.stop()

        elif data_format == 'pivot':
            st.success("âœ… Pivot veri formatÄ± tespit edildi!")
        else:
            st.warning("âš ï¸ Veri formatÄ± tanÄ±namadÄ±. Manuel sÃ¼tun seÃ§imi yapmanÄ±z gerekebilir.")

        # Veri Ã¶nizleme
        st.subheader("ðŸ“Š Veri Ã–nizleme")
        st.dataframe(df.head())

        # SÃ¼tun seÃ§imi
        st.subheader("ðŸ”§ SÃ¼tun SeÃ§imi")
        date_columns, other_columns = parse_date_columns(df)

        c1, c2 = st.columns(2)
        with c1:
            tesisat_col = st.selectbox(
                "Tesisat NumarasÄ± SÃ¼tunu",
                options=other_columns,
                help="Tesisat numarasÄ±nÄ± iÃ§eren sÃ¼tunu seÃ§in"
            )
        with c2:
            bina_col = st.selectbox(
                "Bina NumarasÄ± SÃ¼tunu",
                options=other_columns,
                help="Bina numarasÄ±nÄ± iÃ§eren sÃ¼tunu seÃ§in"
            )

        if date_columns:
            rng = _safe_sort_date_cols(date_columns)
            st.write(f"**Tespit edilen tarih sÃ¼tunlarÄ±:** {len(date_columns)} adet")
            st.write(f"Tarih aralÄ±ÄŸÄ±: {rng[0]} - {rng[-1]}")

        # Analiz butonu
        if st.button("ðŸ” Anomali Analizini BaÅŸlat", type="primary"):
            if not date_columns:
                st.error("âŒ Tarih sÃ¼tunlarÄ± bulunamadÄ±! LÃ¼tfen dosya formatÄ±nÄ± kontrol edin.")
            elif not tesisat_col or not bina_col:
                st.error("âŒ LÃ¼tfen tesisat ve bina sÃ¼tunlarÄ±nÄ± seÃ§in!")
            else:
                with st.spinner("Analiz yapÄ±lÄ±yor..."):
                    results_df = analyze_consumption_patterns(df, date_columns, tesisat_col, bina_col)

                    if not results_df.empty:
                        st.subheader("ðŸ“ˆ Analiz SonuÃ§larÄ±")
                        c1, c2, c3, c4 = st.columns(4)
                        with c1: st.metric("Toplam Tesisat", len(results_df))
                        with c2:
                            suspicious_count = int((results_df['suspicion_level'] == 'ÅžÃ¼pheli').sum())
                            st.metric("ÅžÃ¼pheli Tesisat", suspicious_count)
                        with c3:
                            if len(results_df) > 0:
                                suspicious_rate = (suspicious_count / len(results_df)) * 100
                                st.metric("ÅžÃ¼pheli Oran", f"{suspicious_rate:.1f}%")
                        with c4:
                            total_anomalies = int(results_df['anomali_sayisi'].sum())
                            st.metric("Toplam Anomali", total_anomalies)

                        # GÃ¶rselleÅŸtirmeler
                        st.subheader("ðŸ“Š GÃ¶rselleÅŸtirmeler")
                        create_visualizations(results_df, df, date_columns)

                        # ÅžÃ¼pheli tesisatlar
                        st.subheader("ðŸš¨ ÅžÃ¼pheli Tesisatlar")
                        suspicious_df = results_df[results_df['suspicion_level'] == 'ÅžÃ¼pheli'].copy()

                        if not suspicious_df.empty:
                            display_cols = ['tesisat_no', 'bina_no', 'kis_tuketim', 'yaz_tuketim',
                                            'ortalama_tuketim', 'kis_trend', 'anomali_sayisi', 'anomaliler']
                            suspicious_display = suspicious_df[display_cols].copy()
                            suspicious_display.columns = ['Tesisat No', 'Bina No', 'KÄ±ÅŸ TÃ¼ketim',
                                                          'Yaz TÃ¼ketim', 'Ortalama TÃ¼ketim', 'KÄ±ÅŸ Trend',
                                                          'Anomali SayÄ±sÄ±', 'Anomaliler']
                            for col in ['KÄ±ÅŸ TÃ¼ketim', 'Yaz TÃ¼ketim', 'Ortalama TÃ¼ketim']:
                                suspicious_display[col] = suspicious_display[col].round(1)

                            st.dataframe(suspicious_display, use_container_width=True, hide_index=True)

                            buffer = BytesIO()
                            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                suspicious_display.to_excel(writer, index=False, sheet_name='ÅžÃ¼pheli Tesisatlar')
                            st.download_button(
                                label="ðŸ“¥ ÅžÃ¼pheli TesisatlarÄ± Ä°ndir (Excel)",
                                data=buffer.getvalue(),
                                file_name="supheli_tesisatlar.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        else:
                            st.success("ðŸŽ‰ ÅžÃ¼pheli tesisat bulunamadÄ±!")

                        # TÃ¼m SonuÃ§lar
                        st.subheader("ðŸ“‹ TÃ¼m SonuÃ§lar")

                        filter_col1, filter_col2 = st.columns(2)
                        with filter_col1:
                            suspicion_filter = st.selectbox("ÅžÃ¼pheli Durumu", options=['TÃ¼mÃ¼', 'ÅžÃ¼pheli', 'Normal'], index=0)
                        with filter_col2:
                            bina_list = sorted(results_df['bina_no'].dropna().astype(str).unique().tolist()) if not results_df.empty else []
                            bina_filter = st.selectbox("Bina NumarasÄ±", options=['TÃ¼mÃ¼'] + bina_list, index=0)

                        filtered_df = results_df.copy()
                        if suspicion_filter != 'TÃ¼mÃ¼':
                            filtered_df = filtered_df[filtered_df['suspicion_level'] == suspicion_filter]
                        if bina_filter != 'TÃ¼mÃ¼':
                            filtered_df = filtered_df[filtered_df['bina_no'] == bina_filter]

                        if not filtered_df.empty:
                            display_cols = ['tesisat_no', 'bina_no', 'kis_tuketim', 'yaz_tuketim',
                                            'ortalama_tuketim', 'kis_trend', 'suspicion
